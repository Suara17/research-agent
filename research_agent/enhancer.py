"""
é€šç”¨Agentä¼˜åŒ–é›†æˆæ¨¡å—
å°†æ‰€æœ‰ä¼˜åŒ–ç­–ç•¥æ•´åˆåˆ°agent_loopä¸­
"""
from typing import Dict, List, Optional
import json


class AgentEnhancer:
    """Agentå¢å¼ºå™¨ - æ•´åˆæ‰€æœ‰ä¼˜åŒ–æ¨¡å—"""

    def __init__(self):
        from .entity_graph import EntityRelationshipGraph, extract_entity_graph_from_context, generate_targeted_queries
        from .fallback_strategies import FallbackManager, detect_error_type, extract_entity_name_from_url
        from .reflection import ReflectionManager, ConceptVerifier, should_inject_reflection
        from .answer_synthesis import (
            verify_entity_relationships,
            resolve_timeline,
            extract_candidate_answers,
            synthesize_final_answer,
            validate_answer_format
        )

        self.entity_graph_module = {
            "EntityRelationshipGraph": EntityRelationshipGraph,
            "extract_entity_graph_from_context": extract_entity_graph_from_context,
            "generate_targeted_queries": generate_targeted_queries
        }

        self.fallback_manager = FallbackManager()

        self.reflection_manager = ReflectionManager()
        self.concept_verifier = ConceptVerifier()

        self.answer_synthesis = {
            "verify_entity_relationships": verify_entity_relationships,
            "resolve_timeline": resolve_timeline,
            "extract_candidate_answers": extract_candidate_answers,
            "synthesize_final_answer": synthesize_final_answer,
            "validate_answer_format": validate_answer_format
        }

        self.entity_graph = None  # å½“å‰é—®é¢˜çš„å®ä½“å…³ç³»å›¾
        self.last_reflection_step = -10  # ä¸Šæ¬¡åæ€çš„æ­¥éª¤


    def should_trigger_reflection(
        self,
        step_index: int,
        max_steps: int,
        searched_keywords: List[str]
    ) -> Optional[str]:
        """
        åˆ¤æ–­æ˜¯å¦åº”è¯¥è§¦å‘åæ€ï¼Œå¹¶è¿”å›åæ€æç¤º

        Returns:
            åæ€æç¤ºæ–‡æœ¬ï¼Œå¦‚æœä¸éœ€è¦åæ€åˆ™è¿”å›None
        """
        checkpoint = self.reflection_manager.should_trigger(
            current_step=step_index,
            max_steps=max_steps,
            search_count=len(searched_keywords)
        )

        if checkpoint:
            context = {
                "current_step": step_index,
                "max_steps": max_steps,
                "search_count": len(searched_keywords),
                "recent_keywords": searched_keywords
            }
            prompt = self.reflection_manager.generate_reflection_prompt(checkpoint, context)
            self.last_reflection_step = step_index
            return prompt

        return None


    def handle_web_fetch_failure(
        self,
        url: str,
        error_message: str,
        search_func
    ) -> Optional[Dict]:
        """
        å¤„ç†web_fetchå¤±è´¥ï¼Œå¯ç”¨å›é€€ç­–ç•¥

        Args:
            url: å¤±è´¥çš„URL
            error_message: é”™è¯¯æ¶ˆæ¯
            search_func: web_searchå‡½æ•°å¼•ç”¨

        Returns:
            å›é€€ç­–ç•¥çš„ç»“æœï¼Œå¦‚æœå¤±è´¥è¿”å›None
        """
        from .fallback_strategies import detect_error_type, extract_entity_name_from_url

        error_type = detect_error_type(error_message)
        entity_name = extract_entity_name_from_url(url)

        print(f"[AgentEnhancer] æ£€æµ‹åˆ°web_fetchå¤±è´¥: {url}")
        print(f"[AgentEnhancer] é”™è¯¯ç±»å‹: {error_type}, å®ä½“: {entity_name}")

        result = self.fallback_manager.handle_fetch_failure(
            url=url,
            entity_name=entity_name,
            error_type=error_type,
            search_func=search_func
        )

        return result


    def build_entity_graph(self, question: str, context_messages: List[Dict]) -> bool:
        """
        æ„å»ºå®ä½“å…³ç³»å›¾

        Args:
            question: åŸå§‹é—®é¢˜
            context_messages: ä¸Šä¸‹æ–‡æ¶ˆæ¯åˆ—è¡¨

        Returns:
            æ˜¯å¦æˆåŠŸæ„å»º
        """
        try:
            # æå–å·¥å…·è°ƒç”¨ç»“æœä½œä¸ºä¸Šä¸‹æ–‡
            context = ""
            for msg in context_messages[-10:]:  # åªçœ‹æœ€è¿‘10æ¡æ¶ˆæ¯
                if msg.get("role") == "tool":
                    content = str(msg.get("content", ""))
                    context += content[:500] + "\n"

            from .entity_graph import extract_entity_graph_from_context

            self.entity_graph = extract_entity_graph_from_context(context, question)

            # éªŒè¯ä¸€è‡´æ€§
            is_valid, issues = self.entity_graph.verify_consistency()

            if not is_valid:
                print(f"[AgentEnhancer] å®ä½“å…³ç³»å›¾å‘ç°é€»è¾‘å†²çª:")
                for issue in issues:
                    print(f"  - {issue}")

            # è¯†åˆ«ç¼ºå¤±ä¿¡æ¯
            missing = self.entity_graph.get_missing_information()
            if missing:
                print(f"[AgentEnhancer] å®ä½“å…³ç³»å›¾è¯†åˆ«ç¼ºå¤±ä¿¡æ¯:")
                for m in missing:
                    print(f"  - {m}")

            return True

        except Exception as e:
            print(f"[AgentEnhancer] æ„å»ºå®ä½“å…³ç³»å›¾å¤±è´¥: {e}")
            return False


    def generate_targeted_search_queries(self) -> List[str]:
        """
        åŸºäºå®ä½“å…³ç³»å›¾ç”Ÿæˆé’ˆå¯¹æ€§æœç´¢æŸ¥è¯¢

        Returns:
            æŸ¥è¯¢åˆ—è¡¨
        """
        if not self.entity_graph:
            return []

        from .entity_graph import generate_targeted_queries
        queries = generate_targeted_queries(self.entity_graph)

        print(f"[AgentEnhancer] åŸºäºå®ä½“å›¾ç”Ÿæˆäº† {len(queries)} ä¸ªé’ˆå¯¹æ€§æŸ¥è¯¢")
        return queries


    def verify_concept_understanding(self, question: str, agent_interpretation: str) -> Dict:
        """
        éªŒè¯Agentå¯¹é—®é¢˜çš„æ¦‚å¿µç†è§£

        Args:
            question: åŸå§‹é—®é¢˜
            agent_interpretation: Agentçš„ç†è§£/æœç´¢ç­–ç•¥

        Returns:
            éªŒè¯ç»“æœ
        """
        result = self.concept_verifier.verify_concept_understanding(
            question=question,
            agent_interpretation=agent_interpretation
        )

        if not result.get("is_correct", True):
            print(f"[AgentEnhancer] æ£€æµ‹åˆ°æ¦‚å¿µç†è§£é”™è¯¯:")
            for issue in result.get("issues", []):
                print(f"  âŒ {issue}")
            for suggestion in result.get("suggestions", []):
                print(f"  ğŸ’¡ {suggestion}")

        return result


    def synthesize_answer_from_state(
        self,
        question: str,
        search_results: List[Dict],
        tool_results: List[str]
    ) -> Dict:
        """
        ä»å½“å‰çŠ¶æ€åˆæˆæœ€ç»ˆç­”æ¡ˆ

        Args:
            question: åŸå§‹é—®é¢˜
            search_results: æœç´¢ç»“æœåˆ—è¡¨
            tool_results: å·¥å…·ç»“æœåˆ—è¡¨

        Returns:
            {answer, confidence, reasoning}
        """
        from .answer_synthesis import extract_candidate_answers, synthesize_final_answer, validate_answer_format

        # æå–å€™é€‰ç­”æ¡ˆ
        candidates = extract_candidate_answers(question, search_results, tool_results)

        print(f"[AgentEnhancer] æå–äº† {len(candidates)} ä¸ªå€™é€‰ç­”æ¡ˆ")

        # ç»¼åˆå®ä½“å…³ç³»å›¾
        entity_graph_dict = self.entity_graph.to_dict() if self.entity_graph else None

        # åˆæˆæœ€ç»ˆç­”æ¡ˆ
        result = synthesize_final_answer(question, candidates, entity_graph_dict)

        # éªŒè¯æ ¼å¼
        is_valid, corrected = validate_answer_format(result["answer"], question)

        if not is_valid:
            print(f"[AgentEnhancer] ç­”æ¡ˆæ ¼å¼éªŒè¯å¤±è´¥: {corrected}")
            result["answer"] = corrected
            result["confidence"] *= 0.7  # é™ä½ç½®ä¿¡åº¦

        print(f"[AgentEnhancer] æœ€ç»ˆç­”æ¡ˆ: {result['answer']} (ç½®ä¿¡åº¦: {result['confidence']:.2f})")

        return result


# å…¨å±€å®ä¾‹
_enhancer_instance = None


def get_agent_enhancer() -> AgentEnhancer:
    """è·å–å…¨å±€AgentEnhancerå®ä¾‹"""
    global _enhancer_instance
    if _enhancer_instance is None:
        _enhancer_instance = AgentEnhancer()
    return _enhancer_instance
