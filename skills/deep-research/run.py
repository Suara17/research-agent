#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Deep Research Skill - æ·±åº¦ç ”ç©¶
å¤šæ­¥éª¤æ·±åº¦ç ”ç©¶,é€‚ç”¨äºå¤æ‚é—®é¢˜
"""

import os
import json
import sys

def main():
    try:
        # ä¼˜å…ˆä»ä¸´æ—¶æ–‡ä»¶è¯»å–å‚æ•°ï¼ˆæ–°æ–¹æ¡ˆï¼Œé¿å…è½¬ä¹‰é—®é¢˜ï¼‰
        args_file = os.environ.get("SKILL_ARGS_FILE")

        if args_file and os.path.exists(args_file):
            print(f"[DEBUG] Reading args from file: {args_file}", file=sys.stderr)
            with open(args_file, 'r', encoding='utf-8') as f:
                args = json.load(f)
            print(f"[DEBUG] Loaded args from file successfully", file=sys.stderr)
        else:
            # å…¼å®¹æ—§æ–¹æ¡ˆï¼šä»ç¯å¢ƒå˜é‡è¯»å–
            args_json = os.environ.get("SKILL_ARGS", "{}")
            print(f"[DEBUG] SKILL_ARGS raw value: {repr(args_json)[:200]}", file=sys.stderr)

            args = {}
            if isinstance(args_json, dict):
                args = args_json
            elif isinstance(args_json, str):
                try:
                    args = json.loads(args_json)
                except json.JSONDecodeError as e:
                    print(f"[DEBUG] First parse failed: {e}, trying nested parse", file=sys.stderr)
                    try:
                        args = json.loads(json.loads(args_json))
                    except Exception:
                        if args_json.startswith('"') and args_json.endswith('"'):
                            args_json = args_json[1:-1]
                        args_json_unescaped = args_json.replace('\\"', '"').replace('\\\\', '\\')
                        args = json.loads(args_json_unescaped)

            print(f"[DEBUG] Parsed args successfully", file=sys.stderr)

        # éªŒè¯å‚æ•°ç±»å‹ï¼ˆä¿®å¤ï¼šç§»é™¤é”™è¯¯çš„ç±»å‹æ£€æŸ¥ï¼‰
        if not isinstance(args, dict):
            # å¦‚æœä»ç„¶æ˜¯å­—ç¬¦ä¸²ï¼Œå°è¯•å†æ¬¡è§£æ
            if isinstance(args, str):
                try:
                    args = json.loads(args)
                except:
                    raise TypeError(f"Failed to parse args as JSON: {repr(args)[:200]}")
            else:
                raise TypeError(f"Expected dict, got {type(args).__name__}: {repr(args)[:100]}")

        # æå–å‚æ•°
        query = args.get("query", "")
        depth = args.get("depth", 3)
        focus_areas = args.get("focus_areas", [])

        if not query:
            print(json.dumps({
                "error": "query parameter is required",
                "usage": {
                    "query": "ç ”ç©¶é—®é¢˜",
                    "depth": "ç ”ç©¶æ·±åº¦ (1-5, é»˜è®¤3)",
                    "focus_areas": ["å¯é€‰çš„é‡ç‚¹ç ”ç©¶é¢†åŸŸ"]
                }
            }, ensure_ascii=False))
            sys.exit(1)

        # æ ¹æ®æ·±åº¦ç”Ÿæˆç ”ç©¶è®¡åˆ’
        research_steps = []

        # ç¬¬1æ­¥: åˆå§‹æœç´¢
        research_steps.append({
            "step": 1,
            "phase": "åˆå§‹æ¢ç´¢",
            "actions": [
                {
                    "action": "web_search",
                    "query": f'"{query}" overview',
                    "purpose": "è·å–é—®é¢˜æ¦‚è§ˆ"
                },
                {
                    "action": "web_search",
                    "query": f'"{query}" site:edu OR site:org',
                    "purpose": "å¯»æ‰¾æƒå¨æ¥æº"
                }
            ],
            "expected_output": "è¯†åˆ«3-5ä¸ªé«˜è´¨é‡ä¿¡æ¯æº"
        })

        # ç¬¬2æ­¥: æ·±åº¦é˜…è¯»
        research_steps.append({
            "step": 2,
            "phase": "æ·±åº¦é˜…è¯»",
            "actions": [
                {
                    "action": "web_fetch",
                    "target": "ç¬¬1æ­¥ä¸­è¯†åˆ«çš„æ¯ä¸ªURL",
                    "purpose": "æå–è¯¦ç»†ä¿¡æ¯"
                }
            ],
            "expected_output": "æ ¸å¿ƒäº‹å®å’Œå…³é”®ç»†èŠ‚"
        })

        # ç¬¬3æ­¥: è¡¥å……ç ”ç©¶ (å¦‚æœ depth >= 3)
        if depth >= 3:
            research_steps.append({
                "step": 3,
                "phase": "è¡¥å……éªŒè¯",
                "actions": [
                    {
                        "action": "multi-source-verify",
                        "target": "ç¬¬2æ­¥æå–çš„å…³é”®äº‹å®",
                        "purpose": "å¤šæºéªŒè¯å‡†ç¡®æ€§"
                    },
                    {
                        "action": "web_search",
                        "query": f'"{query}" latest research OR recent developments',
                        "purpose": "å¯»æ‰¾æœ€æ–°è¿›å±•"
                    }
                ],
                "expected_output": "éªŒè¯çš„äº‹å® + æœ€æ–°ä¿¡æ¯"
            })

        # ç¬¬4æ­¥: æ·±åº¦æ¢ç©¶ (å¦‚æœ depth >= 4)
        if depth >= 4:
            research_steps.append({
                "step": 4,
                "phase": "æ·±åº¦æ¢ç©¶",
                "actions": [
                    {
                        "action": "web_search",
                        "query": f'"{query}" case study OR example',
                        "purpose": "å¯»æ‰¾å…·ä½“æ¡ˆä¾‹"
                    },
                    {
                        "action": "web_search",
                        "query": f'"{query}" criticism OR limitations',
                        "purpose": "äº†è§£å±€é™æ€§å’Œæ‰¹è¯„"
                    }
                ],
                "expected_output": "å…¨é¢ç†è§£(åŒ…æ‹¬æ­£åé¢)"
            })

        # ç¬¬5æ­¥: ç»¼åˆåˆ†æ (å¦‚æœ depth == 5)
        if depth >= 5:
            research_steps.append({
                "step": 5,
                "phase": "ç»¼åˆåˆ†æ",
                "actions": [
                    {
                        "action": "chain-of-verification",
                        "target": "ç»¼åˆæ‰€æœ‰ä¿¡æ¯åçš„ç­”æ¡ˆ",
                        "purpose": "æœ€ç»ˆéªŒè¯"
                    }
                ],
                "expected_output": "é«˜ç½®ä¿¡åº¦çš„ç»¼åˆç­”æ¡ˆ"
            })

        # é‡ç‚¹é¢†åŸŸè¡¥å……
        if focus_areas:
            for area in focus_areas:
                research_steps.append({
                    "step": f"ä¸“é¡¹_{area}",
                    "phase": f"é‡ç‚¹ç ”ç©¶: {area}",
                    "actions": [
                        {
                            "action": "web_search",
                            "query": f'"{query}" {area}',
                            "purpose": f"æ·±å…¥ç ”ç©¶{area}æ–¹é¢"
                        }
                    ],
                    "expected_output": f"{area}é¢†åŸŸçš„è¯¦ç»†ä¿¡æ¯"
                })

        # è¾“å‡ºç»“æœ
        result = {
            "status": "success",
            "query": query,
            "research_depth": depth,
            "focus_areas": focus_areas,
            "research_plan": research_steps,
            "estimated_steps": len(research_steps) * 2,  # æ¯æ­¥å¤§çº¦2æ¬¡å·¥å…·è°ƒç”¨
            "tips": [
                "éµå¾ªç ”ç©¶è®¡åˆ’é€æ­¥æ‰§è¡Œ",
                "æ¯ä¸€æ­¥éƒ½è®°å½•å…³é”®å‘ç°",
                "å¦‚æœæŸä¸ªæ¥æºè´¨é‡ä¸é«˜,ç«‹å³å¯»æ‰¾æ›¿ä»£æ¥æº",
                "æœ€åç»¼åˆæ‰€æœ‰ä¿¡æ¯,ç»™å‡ºå®Œæ•´ç­”æ¡ˆ"
            ],
            "quality_checklist": [
                "â–¡ è‡³å°‘3ä¸ªç‹¬ç«‹æ¥æºæ”¯æŒ",
                "â–¡ åŒ…å«æƒå¨æ¥æº (.edu/.gov)",
                "â–¡ äº‹å®ç»è¿‡éªŒè¯",
                "â–¡ æ—¶é—´çº¿ä¸€è‡´",
                "â–¡ æ— æœªè§£å†³çš„çŸ›ç›¾"
            ]
        }

        print(json.dumps(result, ensure_ascii=False, indent=2))

    except Exception as e:
        error_result = {
            "error": str(e),
            "status": "failed",
            "traceback": str(e.__class__.__name__)
        }
        # ğŸ”¥ ä¿®å¤ï¼šé”™è¯¯ä¹Ÿè¾“å‡ºåˆ° stdoutï¼Œè¿™æ ·å¼ºåˆ¶æ‰§è¡Œé€»è¾‘æ‰èƒ½æ•è·
        print(json.dumps(error_result, ensure_ascii=False))
        sys.exit(1)

if __name__ == "__main__":
    main()
