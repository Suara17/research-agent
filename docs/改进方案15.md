基于您提供的代码结构（尤其是 `core.py` 和 `processors.py`）以及之前的运行日志，针对**“谜语类/模糊描述类问题”**（如：“某位曾在20世纪90年代...的人物”）和**提升精准度**，我建议从以下 4 个维度进行深度优化。

这些优化旨在让 Agent 从“**暴力检索**”转向“**推理后检索**”。

---

### 1. 策略层：引入“去匿名化（De-anonymization）”机制

**痛点：** 谜语类问题的核心难点在于**指代不明**。直接搜索谜语的描述（如“针对某财富管理部门”）往往搜不到结果，或者搜出一堆SEO垃圾文。

**优化方案：**
在 `Planner` 或 `smart-search` 之前，增加一个 **Entity Resolution（实体消歧）** 步骤。

**代码逻辑思路：**
在 `core.py` 的 `agent_loop` 开头，或者 Planner Prompt 中加入以下逻辑：

> **[新增 Prompt 策略]**
> “遇到模糊描述（如‘某机构’、‘某大国’、‘某事件’），**严禁直接搜索描述词**。
> **必须**先生成假设候选项，将‘描述’转化为‘具名实体’。
> **Action Pattern:**
> 1. **Analyze**: 提取描述特征（Time: 2020s mid; Type: US SRO; Event: Family Office Disruption）。
> 2. **Hypothesize**: 基于内部知识库猜测实体（Candidate: FINRA?）。
> 3. **Search**: 搜索 `{Candidate Name} + {Event Keyword}` 而不是 `{Description} + {Event Keyword}`。”
> 
> 

**实际效果：**

* **原搜索：** `美国行业自律监管机构 财富管理 调查` (结果模糊)
* **优化后：** Agent 先推理出“美国唯一的证券行业自律机构通常是 FINRA”，然后搜索 `FINRA wealth management investigation 2025`。

---

### 2. 检索层：实现“结构化查询生成（Structured Query Generation）”

**痛点：** 代码中的 `smart-search` 似乎只是简单地由 LLM 生成查询。如果 LLM 只是把问题翻译成英文或提取关键词，对于复杂逻辑往往不够。

**优化方案：**
修改 `smart-search` 的 Prompt（或者在 `core.py` 调用它之前），强制要求生成 **3 类互补的查询**，而不是同质化的查询。

**修改建议（伪代码/Prompt）：**

```python
# 在调用 search 工具前，要求 LLM 生成以下组合：

queries = [
    # 1. 广度搜索 (Broad): 用于确定事件背景
    f"{keywords} market scandal overview",
    
    # 2. 精确搜索 (Precise): 加上 site: 限制，针对权威源
    f"site:sec.gov OR site:finra.org {keywords} enforcement action",
    
    # 3. 否定/排他搜索 (Negative): 如果之前发现了错误路径（如加密货币），主动排除
    f"{keywords} -crypto -bitcoin"
]

```

**针对代码 `core.py` 的改动：**
在 `llm_step` 中，当检测到 Loop（循环）时，强制注入一个 **Negative Constraint（负向约束）**。

* **当前逻辑：** 只是提示 "STOP searching for X"。
* **优化逻辑：** 强制下一条搜索指令必须包含 `-X`（如 `-Archegos` 如果要排除它，或者 `-Crypto`）。

---

### 3. 数据处理层：增加“相关性预判（Relevance Scoring）”

**痛点：** `core.py` 中的 `web_search` 返回结果后，Agent 往往直接把所有摘要塞进 Memory。如果搜索结果有噪音（如之前的“National Mining Museum”），Agent 会被带偏。

**优化方案：**
在 `execute_tools` 环节，在将搜索结果写入 Memory 之前，增加一个**轻量级过滤器**。

**代码实现思路 (`core.py` -> `execute_tools`):**

```python
# 伪代码：在拿到 tool_result_content 后，写入 memory 前
def filter_results(query, raw_results):
    # 使用一个小模型或简单的关键词匹配算法
    valid_results = []
    for res in raw_results:
        # 1. 关键词覆盖率检查
        if calculate_keyword_overlap(query, res['snippet']) < 0.3:
            continue # 丢弃相关性低的结果
        
        # 2. (可选) LLM 快速打分
        # score = llm.predict(f"Is this snippet relevant to '{query}'? Yes/No")
        
        valid_results.append(res)
    return valid_results

```

**作用：** 就像一个漏斗，把不含关键实体（如“2025”、“监管”、“罚款”）的网页直接过滤掉，防止噪音污染上下文。

---

### 4. 流程层：引入 HyDE (Hypothetical Document Embeddings) 思想的简化版

**痛点：** 谜语类问题（如“为了给跨国衍生品交易提供监管确定性...”）的原文往往是非常正式的法律文书，用户的问题是大白话。两者在语义空间上不匹配，导致搜不到。

**优化方案：**
让 Agent 在搜索前，先**“虚构”**一段可能的新闻标题或报告片段。

**Prompt 优化建议：**

> “用户的问题是一个谜语。请想象一下，如果这个事件被主流媒体报道，新闻标题会是什么？或者官方公告的标题会包含哪些词？
> 请生成 3 个**假设性的新闻标题**，然后搜索这些标题。”

**例子：**

* **问题：** “某机构...发布联合声明...基于结果的监管”
* **Agent 虚构标题：**
1. "UK and US regulators joint statement on derivatives"
2. "FCA CFTC cross-border supervision agreement"
3. "outcomes-based regulation mutual recognition"


* **搜索：** 搜索上述虚构标题，命中率通常远高于搜索用户的问题原话。

### 总结建议实施路径

1. **立刻做（低成本）：** 修改 `DEFAULT_SYSTEM_PROMPT`，加入 **“先猜实体，再搜索”** 的思维链（CoT）要求。
2. **稍后做（改代码）：** 在 `core.py` 中，当 `web_search` 返回结果时，如果结果中不包含 Query 中的核心实体（如年份、特定名词），**直接丢弃**该条结果，不写入 Memory。这能极大减少噪音。
3. **高级优化：** 实现 HyDE 策略，让 `smart-search` 不仅生成关键词，还能生成“假设性答案”去反向搜索。