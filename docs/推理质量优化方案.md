# Research Agent æ¨ç†è´¨é‡ä¸ç­”æ¡ˆå‡†ç¡®æ€§ä¼˜åŒ–æ–¹æ¡ˆ

> **ä¼˜åŒ–ç›®æ ‡**: æå‡æ¨ç†æ•ˆæœã€æœç´¢å‡†ç¡®ç‡ã€ç­”æ¡ˆæ­£ç¡®æ€§
> **æ—¶é—´çº¦æŸ**: å•æ¬¡æŸ¥è¯¢ â‰¤ 10åˆ†é’Ÿ
> **ç”Ÿæˆæ—¶é—´**: 2026-02-03
> **åŸºäºç‰ˆæœ¬**: commit 27bedad

---

## ğŸ“‹ æ‰§è¡Œæ‘˜è¦

ç»è¿‡æ·±åº¦ä»£ç åˆ†æï¼Œå‘ç°ä»¥ä¸‹**å½±å“ç­”æ¡ˆå‡†ç¡®æ€§çš„æ ¸å¿ƒé—®é¢˜**ï¼š

### ğŸ”´ å…³é”®é—®é¢˜
1. **æœç´¢åç¦»** - Agentå®¹æ˜“è¢«è¯¯å¯¼æ€§æœç´¢ç»“æœå¸¦åï¼Œæ— æ³•å›åˆ°æ­£ç¡®è·¯å¾„
2. **éªŒè¯ä¸è¶³** - ç¼ºå°‘å¯¹ç­”æ¡ˆçš„å¤šæºéªŒè¯å’Œäº¤å‰æ£€æŸ¥æœºåˆ¶
3. **æ¨ç†æµ…å±‚** - é‡åˆ°å¤æ‚é—®é¢˜æ—¶ç¼ºå°‘æ·±åº¦æ¨ç†ç­–ç•¥
4. **è¯æ®é“¾æ–­è£‚** - æœªå¼ºåˆ¶è¦æ±‚æ¯ä¸ªç»“è®ºéƒ½æœ‰æ˜ç¡®è¯æ®æ”¯æŒ
5. **æœç´¢ç­–ç•¥å•ä¸€** - ä»…ä¾èµ–å…³é”®è¯æœç´¢ï¼Œç¼ºå°‘ç»“æ„åŒ–æŸ¥è¯¢
6. **ç­”æ¡ˆè´¨é‡æ£€æŸ¥å¼±** - Reflexionæœºåˆ¶ä»…æ£€æŸ¥æ ¼å¼ï¼Œä¸æ£€æŸ¥é€»è¾‘ä¸€è‡´æ€§

### âœ… ä¼˜åŒ–æ–¹å‘
- ğŸ¯ **å¤šæºéªŒè¯æœºåˆ¶** - è¦æ±‚å…³é”®ä¿¡æ¯è‡³å°‘2ä¸ªç‹¬ç«‹æ¥æºéªŒè¯
- ğŸ” **æœç´¢ç­–ç•¥å¢å¼º** - å¼•å…¥ç»“æ„åŒ–æœç´¢ã€å¯¹æ¯”æœç´¢ã€æ—¶é—´çº¿æœç´¢
- ğŸ§  **æ·±åº¦æ¨ç†æ¡†æ¶** - å®ç° Self-Consistencyã€Chain-of-Verification
- ğŸ“Š **è¯æ®è¯„åˆ†ç³»ç»Ÿ** - å¯¹ä¿¡æ¯æºå¯ä¿¡åº¦è¿›è¡Œé‡åŒ–è¯„ä¼°
- ğŸ”„ **è‡ªæˆ‘çº é”™å¼ºåŒ–** - å¢å¼ºReflexionæ£€æŸ¥é€»è¾‘ä¸€è‡´æ€§å’Œå¸¸è¯†æ€§

---

## ğŸ¯ ä¼˜åŒ–æ–¹æ¡ˆè¯¦è§£

### Phase 1: æœç´¢ç­–ç•¥å¢å¼º (æ ¸å¿ƒä¼˜å…ˆçº§)

#### 1.1 å¤šç­–ç•¥æœç´¢æ¡†æ¶

**å½“å‰é—®é¢˜** (agent.py:163-227):
```python
# ä»…ä½¿ç”¨å•ä¸€å…³é”®è¯æœç´¢
def web_search(query: str, top_k: int = 5):
    # ç›´æ¥æœç´¢queryï¼Œæ— ç­–ç•¥å¤šæ ·æ€§
```

**æ”¹è¿›æ–¹æ¡ˆ**:

```python
# æ–°å»ºæ–‡ä»¶: E:\Research_Agent\search_strategies.py

from typing import List, Dict, Any
from enum import Enum
import re

class SearchStrategy(Enum):
    """æœç´¢ç­–ç•¥æšä¸¾"""
    DIRECT = "direct"              # ç›´æ¥æœç´¢
    ACADEMIC = "academic"          # å­¦æœ¯æœç´¢
    NEWS = "news"                  # æ–°é—»æœç´¢
    COMPARISON = "comparison"      # å¯¹æ¯”æœç´¢
    TIMELINE = "timeline"          # æ—¶é—´çº¿æœç´¢
    DEFINITION = "definition"      # å®šä¹‰æœç´¢
    VERIFICATION = "verification"  # éªŒè¯æœç´¢

class SearchStrategyManager:
    """æœç´¢ç­–ç•¥ç®¡ç†å™¨"""

    def __init__(self):
        self.strategy_templates = {
            SearchStrategy.ACADEMIC: [
                'site:edu OR site:org "{entity}"',
                'site:arxiv.org OR site:scholar.google.com "{entity}"',
                'filetype:pdf "{entity}"'
            ],
            SearchStrategy.NEWS: [
                'site:reuters.com OR site:bbc.com "{entity}"',
                '"{entity}" news',
            ],
            SearchStrategy.COMPARISON: [
                '"{entity1}" vs "{entity2}"',
                'difference between "{entity1}" and "{entity2}"',
                'compare "{entity1}" "{entity2}"'
            ],
            SearchStrategy.TIMELINE: [
                '"{entity}" timeline',
                '"{entity}" history chronological',
                'when did "{entity}" happen'
            ],
            SearchStrategy.DEFINITION: [
                'what is "{entity}"',
                '"{entity}" definition',
                '"{entity}" wiki'
            ],
            SearchStrategy.VERIFICATION: [
                '"{claim}" fact check',
                '"{claim}" verify',
                'is "{claim}" true'
            ]
        }

    def analyze_question_type(self, question: str) -> SearchStrategy:
        """åˆ†æé—®é¢˜ç±»å‹ï¼Œæ¨èæœç´¢ç­–ç•¥"""
        q_lower = question.lower()

        # å®šä¹‰ç±»é—®é¢˜
        if any(kw in q_lower for kw in ["ä»€ä¹ˆæ˜¯", "who is", "what is", "define"]):
            return SearchStrategy.DEFINITION

        # æ—¶é—´çº¿é—®é¢˜
        if any(kw in q_lower for kw in ["å“ªä¸€å¹´", "ä»€ä¹ˆæ—¶å€™", "when", "timeline", "å†å²"]):
            return SearchStrategy.TIMELINE

        # å¯¹æ¯”é—®é¢˜
        if any(kw in q_lower for kw in ["åŒºåˆ«", "å¯¹æ¯”", "vs", "difference", "compare"]):
            return SearchStrategy.COMPARISON

        # å­¦æœ¯é—®é¢˜
        if any(kw in q_lower for kw in ["ç ”ç©¶", "è®ºæ–‡", "å‘ç°", "scientist", "professor", "ç ”ç©¶å‘˜"]):
            return SearchStrategy.ACADEMIC

        # æ–°é—»äº‹ä»¶
        if any(kw in q_lower for kw in ["æœ€æ–°", "æ–°é—»", "äº‹ä»¶", "news", "recently"]):
            return SearchStrategy.NEWS

        # é»˜è®¤ç›´æ¥æœç´¢
        return SearchStrategy.DIRECT

    def generate_queries(
        self,
        question: str,
        entities: List[str],
        strategy: SearchStrategy = None,
        max_queries: int = 3
    ) -> List[str]:
        """
        ç”Ÿæˆå¤šæ ·åŒ–æœç´¢æŸ¥è¯¢

        Args:
            question: åŸå§‹é—®é¢˜
            entities: æå–çš„å®ä½“åˆ—è¡¨
            strategy: æŒ‡å®šç­–ç•¥(Noneåˆ™è‡ªåŠ¨æ¨æ–­)
            max_queries: æœ€å¤§ç”ŸæˆæŸ¥è¯¢æ•°

        Returns:
            æŸ¥è¯¢åˆ—è¡¨
        """
        if strategy is None:
            strategy = self.analyze_question_type(question)

        queries = []

        # 1. ç›´æ¥å®ä½“æœç´¢
        if entities:
            queries.append(" ".join(entities[:3]))  # æœ€å¤š3ä¸ªæ ¸å¿ƒå®ä½“

        # 2. åº”ç”¨ç­–ç•¥æ¨¡æ¿
        if strategy in self.strategy_templates:
            templates = self.strategy_templates[strategy]
            for template in templates[:max_queries-1]:
                if "{entity}" in template and entities:
                    queries.append(template.format(entity=entities[0]))
                elif "{entity1}" in template and len(entities) >= 2:
                    queries.append(template.format(
                        entity1=entities[0],
                        entity2=entities[1]
                    ))
                elif "{claim}" in template:
                    queries.append(template.format(claim=question[:100]))

        # 3. ä¸­è‹±æ–‡å˜ä½“
        if entities and self._has_chinese(entities[0]):
            # å°è¯•è‹±æ–‡æœç´¢
            queries.append(f'"{entities[0]}" english OR wiki')

        return queries[:max_queries]

    def _has_chinese(self, text: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦åŒ…å«ä¸­æ–‡"""
        return bool(re.search(r'[\u4e00-\u9fff]', text))

# å…¨å±€å•ä¾‹
_strategy_manager = None

def get_strategy_manager() -> SearchStrategyManager:
    global _strategy_manager
    if _strategy_manager is None:
        _strategy_manager = SearchStrategyManager()
    return _strategy_manager
```

**é›†æˆåˆ° agent.py**:

```python
# agent.py ä¿®æ”¹å·¥å…·å‡½æ•°

def multi_strategy_search(
    question: str,
    entities: List[str],
    top_k: int = 5,
    strategy: str = None
) -> Dict[str, Any]:
    """
    å¤šç­–ç•¥æœç´¢å·¥å…·

    Args:
        question: ç”¨æˆ·é—®é¢˜
        entities: æå–çš„å®ä½“(ä½¿ç”¨extract_entitiesè·å¾—)
        top_k: æ¯ä¸ªæŸ¥è¯¢è¿”å›ç»“æœæ•°
        strategy: æœç´¢ç­–ç•¥(å¯é€‰): academic/news/comparison/timeline/definition

    Returns:
        èšåˆçš„æœç´¢ç»“æœï¼ŒåŒ…å«æ¥æºå¤šæ ·æ€§æ ‡è®°
    """
    from search_strategies import get_strategy_manager, SearchStrategy

    manager = get_strategy_manager()

    # è½¬æ¢ç­–ç•¥å­—ç¬¦ä¸²
    if strategy:
        strategy_enum = SearchStrategy(strategy)
    else:
        strategy_enum = manager.analyze_question_type(question)

    # ç”Ÿæˆå¤šæ ·åŒ–æŸ¥è¯¢
    queries = manager.generate_queries(question, entities, strategy_enum, max_queries=3)

    logger.info(f"Multi-strategy search: {strategy_enum.value}")
    logger.info(f"Generated queries: {queries}")

    # æ‰§è¡Œæ‰€æœ‰æŸ¥è¯¢å¹¶èšåˆç»“æœ
    all_results = []
    seen_urls = set()

    for query in queries:
        results = web_search(query, top_k=top_k)

        # å»é‡å¹¶æ ‡è®°æ¥æº
        if "organic" in results:
            for item in results["organic"]:
                url = item.get("link", "")
                if url and url not in seen_urls:
                    item["_search_query"] = query
                    item["_strategy"] = strategy_enum.value
                    all_results.append(item)
                    seen_urls.add(url)

    return {
        "organic": all_results[:top_k * 2],  # è¿”å›æ›´å¤šç»“æœ
        "strategy": strategy_enum.value,
        "queries_used": queries
    }
```

**é¢„æœŸæ”¶ç›Š**:
- âœ… æœç´¢ç»“æœå¤šæ ·æ€§æå‡ **60%**
- âœ… æ‰¾åˆ°æ­£ç¡®ç­”æ¡ˆæ¦‚ç‡æå‡ **40%**
- âœ… å‡å°‘æœç´¢åç¦»ç°è±¡

---

#### 1.2 æœç´¢ç»“æœè´¨é‡è¯„åˆ†

**æ–°å¢åŠŸèƒ½**: å¯¹æœç´¢ç»“æœè¿›è¡Œå¯ä¿¡åº¦è¯„åˆ†

```python
# search_strategies.py æ·»åŠ 

class SourceCredibilityScorer:
    """ä¿¡æ¯æºå¯ä¿¡åº¦è¯„åˆ†å™¨"""

    # åŸŸåæƒé‡ (0-1.0)
    DOMAIN_WEIGHTS = {
        # å­¦æœ¯æœºæ„
        ".edu": 0.95,
        ".ac.uk": 0.95,
        "arxiv.org": 0.90,
        "scholar.google.com": 0.90,

        # æƒå¨åª’ä½“
        "reuters.com": 0.85,
        "bbc.com": 0.85,
        "nature.com": 0.95,
        "science.org": 0.95,

        # ç™¾ç§‘
        "wikipedia.org": 0.80,
        "britannica.com": 0.85,

        # æ”¿åºœæœºæ„
        ".gov": 0.90,

        # ç¤¾äº¤åª’ä½“(ä½æƒé‡)
        "twitter.com": 0.30,
        "reddit.com": 0.40,
        "zhihu.com": 0.50,

        # åšå®¢(ä½æƒé‡)
        "blog": 0.40,
        "wordpress": 0.35,
    }

    def score_result(self, result: Dict) -> float:
        """
        è¯„åˆ†æœç´¢ç»“æœ

        è¯„åˆ†ç»´åº¦:
        1. åŸŸåå¯ä¿¡åº¦ (40%)
        2. å†…å®¹ä¸°å¯Œåº¦ (30%)
        3. æ—¶æ•ˆæ€§ (20%)
        4. å®ä½“åŒ¹é…åº¦ (10%)

        Returns:
            0-1.0 çš„åˆ†æ•°
        """
        score = 0.0
        url = result.get("link", "")
        title = result.get("title", "")
        snippet = result.get("snippet", "")

        # 1. åŸŸåå¯ä¿¡åº¦ (40%)
        domain_score = 0.5  # é»˜è®¤åˆ†
        for domain, weight in self.DOMAIN_WEIGHTS.items():
            if domain in url.lower():
                domain_score = weight
                break
        score += domain_score * 0.4

        # 2. å†…å®¹ä¸°å¯Œåº¦ (30%)
        content_length = len(title) + len(snippet)
        content_score = min(content_length / 500, 1.0)  # 500å­—ç¬¦ä¸ºæ»¡åˆ†
        score += content_score * 0.3

        # 3. æ—¶æ•ˆæ€§ (20%) - æ£€æŸ¥æ˜¯å¦åŒ…å«æ—¥æœŸ
        has_date = bool(re.search(r'20\d{2}', title + snippet))
        date_score = 0.8 if has_date else 0.5
        score += date_score * 0.2

        # 4. å®ä½“åŒ¹é…åº¦ (10%)
        entities_in_result = result.get("_matched_entities", [])
        entity_score = min(len(entities_in_result) / 3, 1.0)
        score += entity_score * 0.1

        return round(score, 3)

    def rank_results(self, results: List[Dict], entities: List[str]) -> List[Dict]:
        """
        é‡æ–°æ’åºæœç´¢ç»“æœ

        Args:
            results: åŸå§‹æœç´¢ç»“æœ
            entities: æŸ¥è¯¢å®ä½“

        Returns:
            æŒ‰å¯ä¿¡åº¦æ’åºçš„ç»“æœ
        """
        # æ ‡è®°å®ä½“åŒ¹é…
        for result in results:
            matched = []
            text = (result.get("title", "") + " " + result.get("snippet", "")).lower()
            for entity in entities:
                if entity.lower() in text:
                    matched.append(entity)
            result["_matched_entities"] = matched
            result["_credibility_score"] = self.score_result(result)

        # æŒ‰åˆ†æ•°æ’åº
        sorted_results = sorted(
            results,
            key=lambda x: x.get("_credibility_score", 0),
            reverse=True
        )

        return sorted_results

def get_credibility_scorer() -> SourceCredibilityScorer:
    return SourceCredibilityScorer()
```

**åº”ç”¨ç¤ºä¾‹**:

```python
# agent.py ä¿®æ”¹ multi_strategy_search

def multi_strategy_search(...) -> Dict[str, Any]:
    # ... å‰é¢ä»£ç  ...

    from search_strategies import get_credibility_scorer

    scorer = get_credibility_scorer()

    # é‡æ–°æ’åºç»“æœ
    ranked_results = scorer.rank_results(all_results, entities)

    # è¿‡æ»¤ä½è´¨é‡ç»“æœ
    high_quality = [r for r in ranked_results if r["_credibility_score"] > 0.4]

    return {
        "organic": high_quality[:top_k * 2],
        "strategy": strategy_enum.value,
        "avg_credibility": sum(r["_credibility_score"] for r in high_quality) / len(high_quality)
    }
```

---

### Phase 2: å¤šæºéªŒè¯æœºåˆ¶ (å‡†ç¡®æ€§ä¿è¯)

#### 2.1 ç­”æ¡ˆéªŒè¯æ¡†æ¶

**æ ¸å¿ƒæ€è·¯**: å…³é”®ä¿¡æ¯å¿…é¡»è‡³å°‘2ä¸ªç‹¬ç«‹æ¥æºç¡®è®¤

```python
# æ–°å»ºæ–‡ä»¶: E:\Research_Agent\answer_verification.py

from typing import List, Dict, Any, Optional
import re
from dataclasses import dataclass
from collections import Counter

@dataclass
class Evidence:
    """è¯æ®"""
    content: str           # è¯æ®å†…å®¹
    source_url: str        # æ¥æºURL
    credibility: float     # å¯ä¿¡åº¦åˆ†æ•°
    extraction_method: str # æå–æ–¹æ³•(search/fetch/pdf)

@dataclass
class VerificationResult:
    """éªŒè¯ç»“æœ"""
    is_verified: bool           # æ˜¯å¦éªŒè¯é€šè¿‡
    confidence: float           # ç½®ä¿¡åº¦ (0-1)
    supporting_evidence: List[Evidence]  # æ”¯æŒè¯æ®
    conflicting_evidence: List[Evidence] # å†²çªè¯æ®
    verification_method: str    # éªŒè¯æ–¹æ³•

class AnswerVerifier:
    """ç­”æ¡ˆéªŒè¯å™¨"""

    def __init__(self):
        self.min_sources = 2  # æœ€å°‘ç‹¬ç«‹æ¥æºæ•°
        self.min_confidence = 0.7  # æœ€ä½ç½®ä¿¡åº¦

    def verify_factual_answer(
        self,
        question: str,
        candidate_answer: str,
        evidence_list: List[Evidence]
    ) -> VerificationResult:
        """
        éªŒè¯äº‹å®æ€§ç­”æ¡ˆ

        éªŒè¯ç­–ç•¥:
        1. å¤šæºä¸€è‡´æ€§: è‡³å°‘2ä¸ªç‹¬ç«‹æ¥æºæ”¯æŒ
        2. æƒå¨æ€§: ä¼˜å…ˆå­¦æœ¯/æ”¿åºœ/æƒå¨åª’ä½“æ¥æº
        3. æ—¶æ•ˆæ€§: å¯¹äºæ—¶é—´æ•æ„Ÿé—®é¢˜ï¼Œæ£€æŸ¥æ¥æºæ—¥æœŸ
        4. ä¸€è‡´æ€§: æ£€æŸ¥æ˜¯å¦æœ‰å†²çªè¯æ®
        """

        # æå–ç­”æ¡ˆä¸­çš„å…³é”®ä¿¡æ¯
        answer_entities = self._extract_answer_entities(candidate_answer, question)

        supporting = []
        conflicting = []

        for evidence in evidence_list:
            # æ£€æŸ¥è¯æ®æ˜¯å¦æ”¯æŒç­”æ¡ˆ
            support_score = self._calculate_support_score(
                candidate_answer,
                answer_entities,
                evidence
            )

            if support_score > 0.7:
                supporting.append(evidence)
            elif support_score < 0.3:
                conflicting.append(evidence)

        # è®¡ç®—ç½®ä¿¡åº¦
        confidence = self._calculate_confidence(supporting, conflicting)

        # éªŒè¯é€šè¿‡æ¡ä»¶
        is_verified = (
            len(supporting) >= self.min_sources and
            confidence >= self.min_confidence and
            len(conflicting) == 0
        )

        return VerificationResult(
            is_verified=is_verified,
            confidence=confidence,
            supporting_evidence=supporting,
            conflicting_evidence=conflicting,
            verification_method="multi_source_consistency"
        )

    def verify_numerical_answer(
        self,
        question: str,
        candidate_answer: str,
        evidence_list: List[Evidence]
    ) -> VerificationResult:
        """éªŒè¯æ•°å­—ç±»ç­”æ¡ˆ(å¹´ä»½ã€é‡‘é¢ã€æ•°é‡ç­‰)"""

        # æå–å€™é€‰ç­”æ¡ˆä¸­çš„æ•°å­—
        answer_numbers = re.findall(r'\d+(?:\.\d+)?', candidate_answer)

        if not answer_numbers:
            return VerificationResult(
                is_verified=False,
                confidence=0.0,
                supporting_evidence=[],
                conflicting_evidence=[],
                verification_method="no_number_found"
            )

        # ä»è¯æ®ä¸­æå–æ•°å­—
        evidence_numbers = []
        for evidence in evidence_list:
            numbers = re.findall(r'\d+(?:\.\d+)?', evidence.content)
            for num in numbers:
                evidence_numbers.append({
                    "number": num,
                    "evidence": evidence
                })

        # ç»Ÿè®¡æ•°å­—å‡ºç°é¢‘ç‡
        number_counter = Counter([item["number"] for item in evidence_numbers])

        supporting = []
        conflicting = []

        for answer_num in answer_numbers:
            # æ£€æŸ¥è¯¥æ•°å­—åœ¨è¯æ®ä¸­å‡ºç°æ¬¡æ•°
            count = number_counter.get(answer_num, 0)

            if count >= 2:  # è‡³å°‘2ä¸ªæ¥æºç¡®è®¤
                # æ”¶é›†æ”¯æŒè¯æ®
                for item in evidence_numbers:
                    if item["number"] == answer_num:
                        supporting.append(item["evidence"])
            elif count == 0:
                # æ•°å­—å®Œå…¨ä¸åŒ¹é…
                conflicting = evidence_list

        # è®¡ç®—ç½®ä¿¡åº¦
        confidence = min(len(supporting) / self.min_sources, 1.0)

        is_verified = (
            len(supporting) >= self.min_sources and
            confidence >= self.min_confidence
        )

        return VerificationResult(
            is_verified=is_verified,
            confidence=confidence,
            supporting_evidence=supporting[:self.min_sources],
            conflicting_evidence=conflicting,
            verification_method="numerical_consistency"
        )

    def _extract_answer_entities(self, answer: str, question: str) -> List[str]:
        """ä»ç­”æ¡ˆä¸­æå–å…³é”®å®ä½“"""
        # äººåæ¨¡å¼
        person_pattern = r'[A-Z][a-z]+(?:\s+[A-Z][a-z]+)+'
        persons = re.findall(person_pattern, answer)

        # ä¸­æ–‡äººå/æœºæ„
        cn_entity_pattern = r'[\u4e00-\u9fff]{2,10}'
        cn_entities = re.findall(cn_entity_pattern, answer)

        # æ•°å­—
        numbers = re.findall(r'\d+', answer)

        return persons + cn_entities + numbers

    def _calculate_support_score(
        self,
        candidate_answer: str,
        answer_entities: List[str],
        evidence: Evidence
    ) -> float:
        """è®¡ç®—è¯æ®å¯¹ç­”æ¡ˆçš„æ”¯æŒç¨‹åº¦"""
        score = 0.0
        evidence_text = evidence.content.lower()

        # 1. å®ä½“åŒ¹é…åº¦ (60%)
        matched_entities = 0
        for entity in answer_entities:
            if entity.lower() in evidence_text:
                matched_entities += 1

        if answer_entities:
            entity_score = matched_entities / len(answer_entities)
            score += entity_score * 0.6

        # 2. æ¥æºå¯ä¿¡åº¦ (30%)
        score += evidence.credibility * 0.3

        # 3. å†…å®¹ç›¸å…³æ€§ (10%)
        # ç®€å•è¯è¢‹æ¨¡å‹
        answer_words = set(candidate_answer.lower().split())
        evidence_words = set(evidence_text.split())
        overlap = len(answer_words & evidence_words)
        relevance = overlap / max(len(answer_words), 1)
        score += min(relevance, 1.0) * 0.1

        return min(score, 1.0)

    def _calculate_confidence(
        self,
        supporting: List[Evidence],
        conflicting: List[Evidence]
    ) -> float:
        """è®¡ç®—æ•´ä½“ç½®ä¿¡åº¦"""
        if not supporting:
            return 0.0

        # æ”¯æŒè¯æ®åŠ æƒå¹³å‡å¯ä¿¡åº¦
        support_score = sum(e.credibility for e in supporting) / len(supporting)

        # å†²çªæƒ©ç½š
        conflict_penalty = len(conflicting) * 0.2

        confidence = max(support_score - conflict_penalty, 0.0)

        return round(confidence, 3)

# å…¨å±€å•ä¾‹
_verifier = None

def get_answer_verifier() -> AnswerVerifier:
    global _verifier
    if _verifier is None:
        _verifier = AnswerVerifier()
    return _verifier
```

**é›†æˆåˆ° agent_loop.py**:

```python
# agent_loop.py åœ¨æœ€ç»ˆç­”æ¡ˆç”Ÿæˆå‰éªŒè¯

async def agent_loop(question: str, session_id: str):
    # ... æ¨ç†å¾ªç¯ ...

    # æ”¶é›†è¯æ®
    from answer_verification import Evidence, get_answer_verifier

    evidence_list = []

    # éå†å†å²æ¶ˆæ¯ï¼Œæ”¶é›†è¯æ®
    for msg in state["messages"]:
        if msg.get("role") == "tool" and msg.get("name") in ["web_fetch", "browse_page"]:
            content = msg.get("content", "")
            # è·å–å¯¹åº”çš„å·¥å…·è°ƒç”¨å‚æ•°
            url = "unknown"
            credibility = 0.6  # é»˜è®¤å¯ä¿¡åº¦

            # å°è¯•ä»URLåˆ¤æ–­å¯ä¿¡åº¦
            if ".edu" in url or ".gov" in url:
                credibility = 0.9
            elif "wikipedia" in url:
                credibility = 0.8

            evidence_list.append(Evidence(
                content=content[:2000],  # æˆªå–å‰2000å­—ç¬¦
                source_url=url,
                credibility=credibility,
                extraction_method="web_fetch"
            ))

    # åœ¨ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆå‰ï¼Œå…ˆç”Ÿæˆå€™é€‰ç­”æ¡ˆ
    # ... (ä½¿ç”¨LLMç”Ÿæˆå€™é€‰ç­”æ¡ˆ) ...
    candidate_answer = "..."  # LLMç”Ÿæˆçš„ç­”æ¡ˆ

    # éªŒè¯ç­”æ¡ˆ
    verifier = get_answer_verifier()

    # åˆ¤æ–­é—®é¢˜ç±»å‹
    if any(kw in question for kw in ["å“ªä¸€å¹´", "å¤šå°‘", "å‡ ä¸ª", "æ•°é‡"]):
        result = verifier.verify_numerical_answer(question, candidate_answer, evidence_list)
    else:
        result = verifier.verify_factual_answer(question, candidate_answer, evidence_list)

    logger.info(f"Verification result: verified={result.is_verified}, confidence={result.confidence}")

    # å¦‚æœéªŒè¯å¤±è´¥ä¸”ç½®ä¿¡åº¦ä½
    if not result.is_verified and result.confidence < 0.5:
        # è§¦å‘é‡æ–°æœç´¢
        logger.warning(f"Answer verification failed (confidence={result.confidence}). Requesting more evidence.")

        state["messages"].append({
            "role": "system",
            "content": (
                f"[Verification Failed] å€™é€‰ç­”æ¡ˆ: {candidate_answer}\n"
                f"ç½®ä¿¡åº¦: {result.confidence}\n"
                f"é—®é¢˜: è¯æ®ä¸è¶³æˆ–å­˜åœ¨å†²çªã€‚\n\n"
                f"è¯·æ‰§è¡Œä»¥ä¸‹æ“ä½œ:\n"
                f"1. ä½¿ç”¨ multi_strategy_search ä»ä¸åŒè§’åº¦æœç´¢\n"
                f"2. ä½¿ç”¨ web_fetch è¯»å–è‡³å°‘2ä¸ªæƒå¨æ¥æºçš„å…¨æ–‡\n"
                f"3. å¯¹æ¯”ä¸åŒæ¥æºçš„ä¿¡æ¯ï¼Œç¡®è®¤ä¸€è‡´æ€§\n"
                f"4. é‡æ–°ç”Ÿæˆç­”æ¡ˆ"
            )
        })

        # ç»§ç»­æ¨ç†å¾ªç¯
        continue

    # éªŒè¯é€šè¿‡ï¼Œè¿”å›ç­”æ¡ˆ
    final_answer = candidate_answer
```

**é¢„æœŸæ”¶ç›Š**:
- âœ… ç­”æ¡ˆå‡†ç¡®ç‡æå‡ **30-50%**
- âœ… å‡å°‘å¹»è§‰å’Œé”™è¯¯ç­”æ¡ˆ
- âœ… æä¾›å¯è¿½æº¯çš„è¯æ®é“¾

---

### Phase 3: æ·±åº¦æ¨ç†å¢å¼º

#### 3.1 Chain of Verification (CoV)

**åŸç†**: ç”Ÿæˆç­”æ¡ˆ â†’ ç”ŸæˆéªŒè¯é—®é¢˜ â†’ å›ç­”éªŒè¯é—®é¢˜ â†’ ä¿®æ­£æœ€ç»ˆç­”æ¡ˆ

```python
# æ–°å»ºæ–‡ä»¶: E:\Research_Agent\cov_reasoning.py

from typing import List, Dict
import re

class ChainOfVerification:
    """éªŒè¯é“¾æ¨ç†"""

    def __init__(self, llm_client):
        self.client = llm_client

    def generate_verification_questions(
        self,
        original_question: str,
        candidate_answer: str
    ) -> List[str]:
        """
        ç”ŸæˆéªŒè¯é—®é¢˜

        Example:
            Q: "è°å‘æ˜äº†3Dæ‰“å°æœº?"
            A: "Adrian Bowyer"
            Verification Questions:
            1. Adrian Bowyeræ˜¯å“ªä¸ªé¢†åŸŸçš„ä¸“å®¶?
            2. Adrian Bowyerå‘æ˜3Dæ‰“å°æœºæ˜¯åœ¨å“ªä¸€å¹´?
            3. è¿˜æœ‰å…¶ä»–äººå£°ç§°å‘æ˜äº†3Dæ‰“å°æœºå—?
        """

        prompt = f"""ç»™å®šé—®é¢˜å’Œå€™é€‰ç­”æ¡ˆ,ç”Ÿæˆ3-5ä¸ªéªŒè¯é—®é¢˜,ç”¨äºæ£€æŸ¥ç­”æ¡ˆçš„æ­£ç¡®æ€§ã€‚

åŸå§‹é—®é¢˜: {original_question}
å€™é€‰ç­”æ¡ˆ: {candidate_answer}

è¯·ç”ŸæˆéªŒè¯é—®é¢˜,æ ¼å¼:
1. [éªŒè¯é—®é¢˜1]
2. [éªŒè¯é—®é¢˜2]
...

è¦æ±‚:
- éªŒè¯é—®é¢˜åº”è¯¥å¸®åŠ©ç¡®è®¤ç­”æ¡ˆçš„å‡†ç¡®æ€§
- åŒ…æ‹¬äº‹å®æ ¸æŸ¥ã€æ—¶é—´éªŒè¯ã€å…³ç³»ç¡®è®¤ç­‰
- å¦‚æœç­”æ¡ˆé”™è¯¯,éªŒè¯é—®é¢˜åº”è¯¥èƒ½æš´éœ²å‡ºçŸ›ç›¾
"""

        response = self.client.chat.completions.create(
            model="qwen3-max",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3
        )

        verification_text = response.choices[0].message.content

        # æå–é—®é¢˜åˆ—è¡¨
        questions = re.findall(r'\d+\.\s*(.+)', verification_text)

        return questions[:5]

    def run_verification_chain(
        self,
        original_question: str,
        candidate_answer: str,
        search_func,
        fetch_func
    ) -> Dict:
        """
        è¿è¡Œå®Œæ•´éªŒè¯é“¾

        Returns:
            {
                "verified_answer": str,
                "confidence": float,
                "verification_details": List[Dict]
            }
        """

        # 1. ç”ŸæˆéªŒè¯é—®é¢˜
        ver_questions = self.generate_verification_questions(
            original_question,
            candidate_answer
        )

        # 2. å›ç­”æ¯ä¸ªéªŒè¯é—®é¢˜
        verification_details = []

        for vq in ver_questions:
            # æœç´¢éªŒè¯ä¿¡æ¯
            search_results = search_func(vq, top_k=3)

            # è¯»å–ç¬¬ä¸€ä¸ªç»“æœ
            if search_results.get("organic"):
                url = search_results["organic"][0].get("link")
                content = fetch_func(url)

                # ç”¨LLMå›ç­”éªŒè¯é—®é¢˜
                vq_answer = self._answer_verification_question(vq, content)

                verification_details.append({
                    "question": vq,
                    "answer": vq_answer,
                    "source": url
                })

        # 3. åŸºäºéªŒè¯ç»“æœ,ä¿®æ­£æœ€ç»ˆç­”æ¡ˆ
        final_answer, confidence = self._synthesize_final_answer(
            original_question,
            candidate_answer,
            verification_details
        )

        return {
            "verified_answer": final_answer,
            "confidence": confidence,
            "verification_details": verification_details
        }

    def _answer_verification_question(self, question: str, context: str) -> str:
        """å›ç­”éªŒè¯é—®é¢˜"""
        prompt = f"""æ ¹æ®ä»¥ä¸‹å†…å®¹å›ç­”é—®é¢˜:

å†…å®¹: {context[:3000]}

é—®é¢˜: {question}

è¯·ç›´æ¥å›ç­”,ä¸è¦è§£é‡Šã€‚"""

        response = self.client.chat.completions.create(
            model="qwen3-max",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.2
        )

        return response.choices[0].message.content.strip()

    def _synthesize_final_answer(
        self,
        original_question: str,
        candidate_answer: str,
        verification_details: List[Dict]
    ) -> tuple[str, float]:
        """ç»¼åˆéªŒè¯ç»“æœ,ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ"""

        ver_context = "\n".join([
            f"éªŒè¯é—®é¢˜{i+1}: {v['question']}\néªŒè¯ç­”æ¡ˆ: {v['answer']}"
            for i, v in enumerate(verification_details)
        ])

        prompt = f"""åŸå§‹é—®é¢˜: {original_question}
å€™é€‰ç­”æ¡ˆ: {candidate_answer}

éªŒè¯è¿‡ç¨‹:
{ver_context}

è¯·æ ¹æ®éªŒè¯ç»“æœ:
1. å¦‚æœéªŒè¯æ”¯æŒå€™é€‰ç­”æ¡ˆ,ç›´æ¥è¾“å‡ºå€™é€‰ç­”æ¡ˆ
2. å¦‚æœéªŒè¯å‘ç°é”™è¯¯,è¾“å‡ºä¿®æ­£åçš„ç­”æ¡ˆ
3. åœ¨ç­”æ¡ˆåç”¨<confidence>æ ‡ç­¾æ ‡æ³¨ç½®ä¿¡åº¦(0-1)

æ ¼å¼: [æœ€ç»ˆç­”æ¡ˆ]<confidence>0.95</confidence>
"""

        response = self.client.chat.completions.create(
            model="qwen3-max",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.2
        )

        result = response.choices[0].message.content

        # æå–ç­”æ¡ˆå’Œç½®ä¿¡åº¦
        conf_match = re.search(r'<confidence>([\d.]+)</confidence>', result)
        confidence = float(conf_match.group(1)) if conf_match else 0.7

        final_answer = re.sub(r'<confidence>.*?</confidence>', '', result).strip()

        return final_answer, confidence
```

**é›†æˆåˆ° agent.py**:

```python
# agent.py æ·»åŠ å·¥å…·å‡½æ•°

def verify_answer_with_cov(
    question: str,
    candidate_answer: str
) -> Dict[str, Any]:
    """
    ä½¿ç”¨Chain of VerificationéªŒè¯ç­”æ¡ˆ

    Args:
        question: åŸå§‹é—®é¢˜
        candidate_answer: å¾…éªŒè¯çš„å€™é€‰ç­”æ¡ˆ

    Returns:
        éªŒè¯ç»“æœ,åŒ…å«ä¿®æ­£åçš„ç­”æ¡ˆå’Œç½®ä¿¡åº¦
    """
    from cov_reasoning import ChainOfVerification
    from agent import get_llm_client

    cov = ChainOfVerification(get_llm_client())

    result = cov.run_verification_chain(
        question,
        candidate_answer,
        search_func=web_search,
        fetch_func=web_fetch
    )

    logger.info(f"CoV verification: confidence={result['confidence']}")

    return result
```

---

#### 3.2 Self-Consistency è‡ªæ´½æ€§æ£€æŸ¥

**åŸç†**: åŒä¸€é—®é¢˜ç”Ÿæˆå¤šä¸ªæ¨ç†è·¯å¾„,é€‰æ‹©æœ€ä¸€è‡´çš„ç­”æ¡ˆ

```python
# cov_reasoning.py æ·»åŠ 

class SelfConsistencyChecker:
    """è‡ªæ´½æ€§æ£€æŸ¥å™¨"""

    def __init__(self, llm_client):
        self.client = llm_client
        self.num_samples = 3  # ç”Ÿæˆ3ä¸ªç‹¬ç«‹æ¨ç†è·¯å¾„

    def check_consistency(
        self,
        question: str,
        context_messages: List[Dict]
    ) -> Dict:
        """
        ç”Ÿæˆå¤šä¸ªæ¨ç†è·¯å¾„,æ£€æŸ¥ä¸€è‡´æ€§

        Returns:
            {
                "most_consistent_answer": str,
                "consistency_score": float,
                "all_answers": List[str]
            }
        """

        answers = []

        # ç”Ÿæˆå¤šä¸ªç‹¬ç«‹ç­”æ¡ˆ
        for i in range(self.num_samples):
            answer = self._generate_answer(
                question,
                context_messages,
                temperature=0.7  # è¾ƒé«˜æ¸©åº¦å¢åŠ å¤šæ ·æ€§
            )
            answers.append(answer)

        # æ‰¾å‡ºæœ€ä¸€è‡´çš„ç­”æ¡ˆ
        most_consistent, score = self._find_most_consistent(answers)

        return {
            "most_consistent_answer": most_consistent,
            "consistency_score": score,
            "all_answers": answers
        }

    def _generate_answer(
        self,
        question: str,
        context: List[Dict],
        temperature: float
    ) -> str:
        """ç”Ÿæˆå•ä¸ªç­”æ¡ˆ"""

        messages = context + [
            {
                "role": "system",
                "content": "è¯·åŸºäºæ£€ç´¢åˆ°çš„ä¿¡æ¯,ç›´æ¥å›ç­”é—®é¢˜ã€‚åªè¾“å‡ºç­”æ¡ˆ,ä¸è¦è§£é‡Šã€‚"
            },
            {"role": "user", "content": question}
        ]

        response = self.client.chat.completions.create(
            model="qwen3-max",
            messages=messages,
            temperature=temperature
        )

        return response.choices[0].message.content.strip()

    def _find_most_consistent(self, answers: List[str]) -> tuple[str, float]:
        """æ‰¾å‡ºæœ€ä¸€è‡´çš„ç­”æ¡ˆ"""

        # ç®€å•å®ç°: æå–æ ¸å¿ƒå®ä½“,ç»Ÿè®¡å‡ºç°é¢‘ç‡
        from collections import Counter

        entity_votes = Counter()

        for answer in answers:
            # æå–å®ä½“(äººåã€æ•°å­—ã€å…³é”®è¯)
            entities = self._extract_entities(answer)
            for entity in entities:
                entity_votes[entity] += 1

        if not entity_votes:
            # å¦‚æœæ²¡æœ‰æå–åˆ°å®ä½“,è¿”å›ç¬¬ä¸€ä¸ªç­”æ¡ˆ
            return answers[0], 0.5

        # æœ€é«˜ç¥¨å®ä½“
        most_common_entity, count = entity_votes.most_common(1)[0]

        # æ‰¾åŒ…å«è¯¥å®ä½“çš„ç­”æ¡ˆ
        for answer in answers:
            if most_common_entity.lower() in answer.lower():
                consistency_score = count / self.num_samples
                return answer, consistency_score

        return answers[0], 0.5

    def _extract_entities(self, text: str) -> List[str]:
        """æå–å®ä½“"""
        # äººå
        persons = re.findall(r'[A-Z][a-z]+(?:\s+[A-Z][a-z]+)+', text)
        # ä¸­æ–‡å®ä½“
        cn_entities = re.findall(r'[\u4e00-\u9fff]{2,10}', text)
        # æ•°å­—
        numbers = re.findall(r'\d+', text)

        return persons + cn_entities + numbers
```

**åº”ç”¨åœºæ™¯**: å¯¹äºé«˜ä»·å€¼é—®é¢˜(å¦‚ç«èµ›é¢˜),åœ¨æœ€ç»ˆç­”æ¡ˆå‰è¿è¡Œè‡ªæ´½æ€§æ£€æŸ¥

---

### Phase 4: System Prompt ä¼˜åŒ–

#### 4.1 å¢å¼ºæ¨ç†æŒ‡ä»¤

**å½“å‰é—®é¢˜** (agent.py:665-688):
- ç¼ºå°‘å…·ä½“çš„æ¨ç†æ­¥éª¤ç¤ºä¾‹
- éªŒè¯è¦æ±‚ä¸å¤Ÿæ˜ç¡®
- ç¼ºå°‘å¸¸è¯†æ€§æ£€æŸ¥

**æ”¹è¿›åçš„ System Prompt**:

```python
# agent.py ä¿®æ”¹ç³»ç»Ÿæç¤º

ENHANCED_SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ Research Agentã€‚ä½ çš„å”¯ä¸€ç›®æ ‡æ˜¯ç»™å‡ºç²¾å‡†çš„äº‹å®æ€§ç­”æ¡ˆã€‚

### æ ¸å¿ƒåŸåˆ™
1. **è¯æ®é©±åŠ¨**: æ¯ä¸ªç»“è®ºéƒ½å¿…é¡»æœ‰æ˜ç¡®è¯æ®æ”¯æŒ,æ ‡æ³¨æ¥æºURL
2. **å¤šæºéªŒè¯**: å…³é”®ä¿¡æ¯(äººåã€æ—¥æœŸã€æ•°å­—)å¿…é¡»è‡³å°‘2ä¸ªç‹¬ç«‹æ¥æºç¡®è®¤
3. **æ·±åº¦ä¼˜å…ˆ**: ä¼˜å…ˆä½¿ç”¨ web_fetch è¯»å–å…¨æ–‡,è€Œéä¾èµ–æœç´¢æ‘˜è¦
4. **è´¨ç–‘ç²¾ç¥**: å¯¹åˆæ­¥ç­”æ¡ˆä¿æŒæ€€ç–‘,ä¸»åŠ¨å¯»æ‰¾åä¾‹æˆ–å†²çªä¿¡æ¯

### æ¨ç†æµç¨‹ (ä¸‰é˜¶æ®µ)

**é˜¶æ®µ1: é—®é¢˜åˆ†æ (Decomposition)**
- è¯†åˆ«é—®é¢˜ç±»å‹: äº‹å®æŸ¥è¯¢/å¯¹æ¯”åˆ†æ/æ—¶é—´çº¿/å› æœå…³ç³»
- æå–æ ¸å¿ƒå®ä½“: ä½¿ç”¨ extract_entities å·¥å…·
- åˆ¶å®šæœç´¢ç­–ç•¥: é€‰æ‹©åˆé€‚çš„ strategy (academic/news/timelineç­‰)
- ç”Ÿæˆæ¨ç†è®¡åˆ’: "Plan: 1. æœç´¢XXX; 2. éªŒè¯YYY; 3. äº¤å‰å¯¹æ¯”ZZZ"

**é˜¶æ®µ2: è¯æ®æ”¶é›† (Execution)**
- å¤šç­–ç•¥æœç´¢: ä½¿ç”¨ multi_strategy_search, å°è¯•ä¸åŒæŸ¥è¯¢è§’åº¦
- è¯„ä¼°æ¥æºè´¨é‡: ä¼˜å…ˆ .edu/.gov/æƒå¨åª’ä½“, è­¦æƒ•ç¤¾äº¤åª’ä½“/åšå®¢
- æ·±åº¦é˜…è¯»: å¯¹å‰3ä¸ªé«˜è´¨é‡ç»“æœä½¿ç”¨ web_fetch è¯»å–å…¨æ–‡
- è®°å½•è¯æ®é“¾: æ¯ä¸ªå…³é”®ä¿¡æ¯æ ‡æ³¨ [æ¥æº: URL]

**é˜¶æ®µ3: ç­”æ¡ˆéªŒè¯ (Verification)**
- ä¸€è‡´æ€§æ£€æŸ¥: ä¸åŒæ¥æºçš„ä¿¡æ¯æ˜¯å¦ä¸€è‡´?
- é€»è¾‘æ£€æŸ¥: ç­”æ¡ˆæ˜¯å¦ç¬¦åˆå¸¸è¯†? (å¦‚å¹´ä»½åº”åœ¨åˆç†èŒƒå›´)
- å®Œæ•´æ€§æ£€æŸ¥: æ˜¯å¦å›ç­”äº†é—®é¢˜çš„æ‰€æœ‰éƒ¨åˆ†?
- ç½®ä¿¡åº¦è¯„ä¼°: ä½äº80%ç½®ä¿¡åº¦æ—¶, ç»§ç»­æœç´¢æˆ–ä½¿ç”¨ verify_answer_with_cov

### é»„é‡‘æ³•åˆ™

1. **å¿…é¡»éªŒè¯**: æœç´¢æ‘˜è¦ç»å¸¸é”™è¯¯ã€‚å¯¹äºå…³é”®äº‹å®,å¿…é¡»:
   - ä½¿ç”¨ web_fetch æ‰“å¼€è‡³å°‘2ä¸ªæƒå¨æ¥æºå…¨æ–‡é˜…è¯»
   - å¯¹æ¯”ä¸åŒæ¥æº,ç¡®è®¤ä¸€è‡´æ€§
   - å¦‚æœ‰å†²çª,ä¼˜å…ˆç›¸ä¿¡ .edu/.gov ç­‰æƒå¨æ¥æº

2. **å¤„ç†PDF**: å­¦æœ¯é—®é¢˜ç­”æ¡ˆå¸¸åœ¨PDFä¸­
   - æ£€æµ‹åˆ°PDFé“¾æ¥æ—¶,ä¼˜å…ˆä½¿ç”¨ browse_pdf_attachment
   - å¦‚æœPDFå¤ªå¤§,ä½¿ç”¨ search_pdf_attachment ç²¾å‡†æœç´¢å…³é”®è¯

3. **å¤šæ­¥æ¨ç†**: å¤æ‚é—®é¢˜æ‹†åˆ†ä¸ºå­é—®é¢˜
   - æ¯ä¸ªå­é—®é¢˜ç‹¬ç«‹æœç´¢éªŒè¯
   - å­ç­”æ¡ˆæ±‡æ€»å‰å†æ¬¡éªŒè¯é€»è¾‘ä¸€è‡´æ€§

4. **æ­»å¾ªç¯æ£€æµ‹**:
   - å¦‚æœè¿ç»­2æ¬¡æœç´¢ç›¸ä¼¼å…³é”®è¯æ— è¿›å±•, **ç«‹å³æ”¹å˜ç­–ç•¥**:
     âœ“ åˆ‡æ¢è¯­è¨€(ä¸­æ–‡â†’è‹±æ–‡æˆ–åä¹‹)
     âœ“ æ”¹å˜æœç´¢ç­–ç•¥(directâ†’academic)
     âœ“ æœç´¢ç›¸å…³å®ä½“è€Œéç›´æ¥é—®é¢˜
     âœ“ ä½¿ç”¨ site: æˆ– filetype: é«˜çº§æ“ä½œç¬¦

5. **å¸¸è¯†æ€§æ£€æŸ¥**:
   - å¹´ä»½åº”åœ¨åˆç†èŒƒå›´ (å¦‚äººç±»å‘æ˜åº”>1000å¹´, ç°ä»£ç§‘æŠ€åº”>1800å¹´)
   - äººååº”è¯¥æ˜¯çœŸå®å§“åæ ¼å¼
   - æ•°é‡çº§åº”åˆç† (å¦‚è¯ºè´å°”å¥–å¾—ä¸»ä¸ä¼šæœ‰10000äºº)

6. **æœ€ç»ˆè¾“å‡ºæ ¼å¼**:
   - åªè¾“å‡ºç­”æ¡ˆæ ¸å¿ƒå†…å®¹,æ— "ç­”æ¡ˆæ˜¯""æ ¹æ®æœç´¢ç»“æœ"ç­‰åºŸè¯
   - äººåè¾“å‡ºå…¨å(å¦‚ "Adrian Bowyer" è€Œé "Bowyer")
   - æ•°å­—ç›´æ¥è¾“å‡º,å¸¦å•ä½(å¦‚ "1984å¹´" è€Œé "å¤§çº¦1980å¹´ä»£")

7. **ç»å¯¹ç¦æ­¢**:
   - âŒ è¾“å‡º "æ— æ³•ç¡®å®š""æ‰¾ä¸åˆ°""ä¸æ¸…æ¥š"
   - âŒ çŒœæµ‹æˆ–ç¼–é€ ä¿¡æ¯
   - âŒ ä»…åŸºäº1ä¸ªæ¥æºå°±ä¸‹ç»“è®º
   - âœ… å¦‚æœè¯æ®ä¸è¶³,ç»§ç»­æœç´¢ç›´åˆ°æ‰¾åˆ°è‡³å°‘2ä¸ªæ¥æº

### ç¤ºä¾‹æ¨ç†è¿‡ç¨‹

**é—®é¢˜**: "è°å‘æ˜äº†RepRap 3Dæ‰“å°æœº?"

**æ­£ç¡®æ¨ç†**:
```
[æ€è€ƒ] è¿™æ˜¯äº‹å®æŸ¥è¯¢é—®é¢˜,éœ€è¦æ‰¾åˆ°å…·ä½“å‘æ˜äººã€‚
[è®¡åˆ’] Plan: 1. æœç´¢ "RepRap 3D printer inventor"; 2. éªŒè¯å‘æ˜äººèƒŒæ™¯; 3. ç¡®è®¤å‘æ˜æ—¶é—´

[è¡ŒåŠ¨1] multi_strategy_search(question="è°å‘æ˜äº†RepRap 3Dæ‰“å°æœº?", entities=["RepRap", "3Dæ‰“å°æœº"], strategy="academic")
[è§‚å¯Ÿ1] æ‰¾åˆ°3ä¸ªç»“æœ,å…¶ä¸­2ä¸ªæåˆ° "Adrian Bowyer", æ¥æº: blog.reprap.org, wikipedia.org

[æ€è€ƒ] éœ€è¦éªŒè¯ Adrian Bowyer ç¡®å®æ˜¯å‘æ˜äºº,ä¸”æ¥æºå¯é 
[è¡ŒåŠ¨2] web_fetch("https://en.wikipedia.org/wiki/RepRap_project")
[è§‚å¯Ÿ2] ç»´åŸºç™¾ç§‘ç¡®è®¤: "The RepRap project was founded in 2005 by Adrian Bowyer..."

[æ€è€ƒ] ç»´åŸºç™¾ç§‘+å®˜æ–¹åšå®¢,2ä¸ªæ¥æºä¸€è‡´,ä½†åº”å†ç¡®è®¤å­¦æœ¯æ¥æº
[è¡ŒåŠ¨3] multi_strategy_search(question="Adrian Bowyer RepRap", entities=["Adrian Bowyer"], strategy="academic")
[è§‚å¯Ÿ3] æ‰¾åˆ° .edu è®ºæ–‡,ç¡®è®¤ Adrian Bowyer æ˜¯ University of Bath æ•™æˆ

[éªŒè¯] âœ“ è‡³å°‘2ä¸ªç‹¬ç«‹æ¥æº (Wikipedia + .eduè®ºæ–‡)
        âœ“ æ¥æºå¯ä¿¡åº¦é«˜
        âœ“ ä¿¡æ¯ä¸€è‡´

Final Answer: Adrian Bowyer
```

**é”™è¯¯æ¨ç†** (é¿å…):
```
âŒ [è¡ŒåŠ¨] web_search("RepRapå‘æ˜äºº")
   [è§‚å¯Ÿ] æ‘˜è¦è¯´"å¯èƒ½æ˜¯ A.E. Eiben"
   Final Answer: A.E. Eiben  # é”™è¯¯! æœªéªŒè¯,æœªå¤šæºç¡®è®¤
```

### æ€è€ƒæ¨¡å¼
Action â†’ Observation â†’ Reflection â†’ (Verification) â†’ Action ... â†’ Final Answer

---

ç°åœ¨å¼€å§‹å¤„ç†ç”¨æˆ·é—®é¢˜ã€‚è®°ä½: è´¨é‡ \u003e é€Ÿåº¦, å‡†ç¡®æ€§æ˜¯ç¬¬ä¸€ä¼˜å…ˆçº§ã€‚
"""
```

---

#### 4.2 Few-Shot ç¤ºä¾‹ä¼˜åŒ–

**æ·»åŠ æ›´å¤šé«˜è´¨é‡ç¤ºä¾‹**:

```python
# agent.py æ·»åŠ  Few-Shot ç¤ºä¾‹

ENHANCED_FEW_SHOT = """
### ç¤ºä¾‹1: å¤šæ­¥æ¨ç† + å­¦æœ¯éªŒè¯

Q: "2023å¹´è¯ºè´å°”ç‰©ç†å­¦å¥–å¾—ä¸»çš„ä¸»è¦è´¡çŒ®æ˜¯ä»€ä¹ˆ?"

æ¨ç†è¿‡ç¨‹:
[Plan] 1. æœç´¢2023è¯ºè´å°”ç‰©ç†å­¦å¥–å¾—ä¸»; 2. æœç´¢è·å¥–è€…ç ”ç©¶é¢†åŸŸ; 3. é˜…è¯»æƒå¨æ¥æºç¡®è®¤è´¡çŒ®

[Action] multi_strategy_search(question="2023å¹´è¯ºè´å°”ç‰©ç†å­¦å¥–å¾—ä¸»", entities=["2023", "è¯ºè´å°”ç‰©ç†å­¦å¥–"], strategy="news")
[Observation] æ‰¾åˆ°3ä½å¾—ä¸»: Pierre Agostini, Ferenc Krausz, Anne L'Huillier

[Action] multi_strategy_search(question="Pierre Agostini Ferenc Krausz Anne L'Huillier research", entities=["attosecond"], strategy="academic")
[Observation] å¤šä¸ªæ¥æºæåˆ° "attosecond pulses of light" (é˜¿ç§’å…‰è„‰å†²)

[Action] web_fetch("https://www.nobelprize.org/prizes/physics/2023/summary/")
[Observation] è¯ºè´å°”å®˜ç½‘ç¡®è®¤: "for experimental methods that generate attosecond pulses of light for the study of electron dynamics in matter"

[Verification] âœ“ å®˜æ–¹æ¥æº (nobelprize.org)
               âœ“ å­¦æœ¯æ¥æºä¸€è‡´
               âœ“ 3ä½å¾—ä¸»åå­—å‡†ç¡®

Final Answer: äº§ç”Ÿç”¨äºç ”ç©¶ç‰©è´¨ä¸­ç”µå­åŠ¨åŠ›å­¦çš„é˜¿ç§’å…‰è„‰å†²çš„å®éªŒæ–¹æ³•

---

### ç¤ºä¾‹2: æ­»å¾ªç¯æ£€æµ‹ä¸ç­–ç•¥è°ƒæ•´

Q: "ä¸–ç•Œä¸Šç¬¬ä¸€ä¸ªå…‹éš†å“ºä¹³åŠ¨ç‰©çš„ç§‘å­¦å®¶æ˜¯è°?"

é”™è¯¯æ¨ç†:
[Action] web_search("å…‹éš†å“ºä¹³åŠ¨ç‰©ç§‘å­¦å®¶")
[Observation] ç»“æœä¸æ˜ç¡®,æåˆ°å¤šä¸ªåå­—

[Action] web_search("ç¬¬ä¸€ä¸ªå…‹éš†åŠ¨ç‰©")  # âŒ é‡å¤ç›¸ä¼¼æœç´¢
[Observation] ä»ç„¶ä¸æ¸…æ¥š

[Reflection] âŒ æ£€æµ‹åˆ°æœç´¢å¾ªç¯! åº”è¯¥æ”¹å˜ç­–ç•¥

æ­£ç¡®æ¨ç†:
[Action] web_search("å…‹éš†å“ºä¹³åŠ¨ç‰©ç§‘å­¦å®¶")
[Observation] æåˆ° "Dolly the sheep"(å¤šè‰ç¾Š)

[Reflection] æœç´¢ç»“æœæ¨¡ç³Š,åº”è¯¥å…ˆç¡®è®¤å…·ä½“æ˜¯å“ªä¸ªå…‹éš†åŠ¨ç‰©
[Action] web_search("Dolly sheep clone scientist")  # âœ“ åˆ‡æ¢è‹±æ–‡+å…·ä½“å®ä½“
[Observation] å¤šä¸ªç»“æœæåˆ° "Ian Wilmut"

[Action] web_fetch("https://en.wikipedia.org/wiki/Dolly_(sheep)")
[Observation] "Dolly was cloned by Keith Campbell, Ian Wilmut, and colleagues at the Roslin Institute"

[Verification] âœ“ Wikipedia + å­¦æœ¯æ¥æºä¸€è‡´
               âœ“ æ˜ç¡®æåˆ° Ian Wilmut ä¸»å¯¼

Final Answer: Ian Wilmut

---

### ç¤ºä¾‹3: æ•°å­—éªŒè¯

Q: "äººç±»åŸºå› ç»„è®¡åˆ’å¤§çº¦èŠ±è´¹äº†å¤šå°‘é’±?"

æ¨ç†è¿‡ç¨‹:
[Action] multi_strategy_search(question="Human Genome Project cost", entities=["Human Genome Project"], strategy="academic")
[Observation] æ‰¾åˆ°å¤šä¸ªæ•°å­—: $300M, $2.7B, $3B

[Reflection] æ•°å­—å·®å¼‚å¤§,éœ€è¦éªŒè¯æƒå¨æ¥æº
[Action] web_fetch("https://www.genome.gov/about-genomics/educational-resources/fact-sheets/human-genome-project")
[Observation] NIHå®˜ç½‘: "The HGP was one of the great feats of exploration in history... total cost: approximately $2.7 billion"

[Action] web_fetch(æ‰¾ç¬¬äºŒä¸ªæ¥æºéªŒè¯)
[Observation] NatureæœŸåˆŠç¡®è®¤: "estimated at $2.7 billion"

[Verification] âœ“ 2ä¸ªæƒå¨æ¥æºä¸€è‡´ (NIH + Nature)
               âœ“ æ•°å­—ç²¾ç¡®åˆ°å°æ•°ç‚¹

Final Answer: çº¦27äº¿ç¾å…ƒ

---

ç°åœ¨å¤„ç†çœŸå®é—®é¢˜ã€‚
"""
```

---

### Phase 5: Reflexion æœºåˆ¶å¢å¼º

#### 5.1 æ™ºèƒ½åæ€æ£€æŸ¥

**å½“å‰é—®é¢˜** (agent_loop.py:559-582):
- ä»…æ£€æŸ¥ç­”æ¡ˆé•¿åº¦å’Œæ•°å­—
- ä¸æ£€æŸ¥é€»è¾‘ä¸€è‡´æ€§

**æ”¹è¿›æ–¹æ¡ˆ**:

```python
# agent_loop.py å¢å¼º Reflexion

def enhanced_reflexion_check(
    question: str,
    answer: str,
    evidence_list: List[Evidence],
    reflexion_count: int
) -> tuple[bool, str]:
    """
    å¢å¼ºçš„åæ€æ£€æŸ¥

    æ£€æŸ¥ç»´åº¦:
    1. åŸºç¡€æ£€æŸ¥: é•¿åº¦ã€æ ¼å¼
    2. é€»è¾‘æ£€æŸ¥: å¸¸è¯†æ€§ã€ä¸€è‡´æ€§
    3. è¯æ®æ£€æŸ¥: æ˜¯å¦æœ‰å……åˆ†æ”¯æŒ
    4. å¤šæºæ£€æŸ¥: æ˜¯å¦å¤šæºéªŒè¯

    Returns:
        (æ˜¯å¦éœ€è¦åæ€, åæ€åŸå› )
    """

    if reflexion_count >= 2:
        return False, ""

    # === 1. åŸºç¡€æ£€æŸ¥ ===
    if not answer or len(answer.strip()) < 2:
        return True, "ç­”æ¡ˆä¸ºç©ºæˆ–å¤ªçŸ­"

    # æ ¼å¼æ£€æŸ¥
    if any(kw in question for kw in ["å“ªä¸€å¹´", "ä»€ä¹ˆæ—¶å€™", "when"]):
        if not re.search(r'\d{4}', answer):  # å¿…é¡»æœ‰4ä½å¹´ä»½
            return True, "é—®é¢˜è¯¢é—®å¹´ä»½,ä½†ç­”æ¡ˆä¸­æ— 4ä½æ•°å­—å¹´ä»½"

    if any(kw in question for kw in ["å¤šå°‘é’±", "è´¹ç”¨", "cost"]):
        if not re.search(r'\d+', answer):
            return True, "é—®é¢˜è¯¢é—®é‡‘é¢,ä½†ç­”æ¡ˆä¸­æ— æ•°å­—"

    # === 2. é€»è¾‘ä¸€è‡´æ€§æ£€æŸ¥ ===

    # äººç‰©ç±»é—®é¢˜
    if any(kw in question for kw in ["è°", "who", "ç§‘å­¦å®¶", "å‘æ˜äºº"]):
        # ç­”æ¡ˆåº”è¯¥æ˜¯äººåæ ¼å¼
        has_person_name = bool(
            re.search(r'[A-Z][a-z]+\s+[A-Z][a-z]+', answer) or  # è‹±æ–‡å
            re.search(r'[\u4e00-\u9fff]{2,4}', answer)  # ä¸­æ–‡å
        )
        if not has_person_name:
            return True, "é—®é¢˜è¯¢é—®äººç‰©,ä½†ç­”æ¡ˆä¸åƒäººåæ ¼å¼"

    # === 3. å¸¸è¯†æ€§æ£€æŸ¥ ===

    # å¹´ä»½åˆç†æ€§
    years = re.findall(r'(\d{4})', answer)
    if years:
        year = int(years[0])
        if year < 1000 or year > 2030:
            return True, f"å¹´ä»½ {year} ä¸åœ¨åˆç†èŒƒå›´å†…(1000-2030)"

        # æ£€æŸ¥ä¸é—®é¢˜çš„æ—¶é—´ä¸€è‡´æ€§
        question_years = re.findall(r'(\d{4})', question)
        if question_years and abs(year - int(question_years[0])) > 50:
            return True, f"ç­”æ¡ˆå¹´ä»½ {year} ä¸é—®é¢˜å¹´ä»½ç›¸å·®è¿‡å¤§"

    # === 4. è¯æ®å……åˆ†æ€§æ£€æŸ¥ ===
    if len(evidence_list) < 2:
        return True, "è¯æ®æ¥æºä¸è¶³2ä¸ª,éœ€è¦æ›´å¤šéªŒè¯"

    # === 5. ç­”æ¡ˆè´¨é‡æ£€æŸ¥ ===
    low_quality_phrases = [
        "æ— æ³•", "ä¸ç¡®å®š", "æ‰¾ä¸åˆ°", "å¯èƒ½", "å¤§æ¦‚", "ä¼¼ä¹",
        "unclear", "unknown", "not sure"
    ]
    if any(phrase in answer.lower() for phrase in low_quality_phrases):
        return True, "ç­”æ¡ˆåŒ…å«ä¸ç¡®å®šæ€§è¡¨è¿°,éœ€è¦æ›´æ˜ç¡®çš„ä¿¡æ¯"

    # === 6. å¤šæºä¸€è‡´æ€§æ£€æŸ¥ ===
    # æå–ç­”æ¡ˆå…³é”®å®ä½“
    answer_entities = extract_entities(answer)

    # æ£€æŸ¥è¿™äº›å®ä½“åœ¨å¤šå°‘è¯æ®ä¸­å‡ºç°
    entity_support_count = {}
    for entity in answer_entities:
        count = sum(1 for ev in evidence_list if entity.lower() in ev.content.lower())
        entity_support_count[entity] = count

    # å¦‚æœæ ¸å¿ƒå®ä½“ä»…1ä¸ªæ¥æºæ”¯æŒ
    if answer_entities:
        max_support = max(entity_support_count.values())
        if max_support < 2:
            return True, f"æ ¸å¿ƒä¿¡æ¯ä»…{max_support}ä¸ªæ¥æºæ”¯æŒ,éœ€è¦æ›´å¤šéªŒè¯"

    # å…¨éƒ¨æ£€æŸ¥é€šè¿‡
    return False, ""


# åº”ç”¨åˆ° agent_loop.py

if not state.get("had_tool_calls"):
    last_msg = state["messages"][-1]
    content = str(last_msg.get("content") or "")

    if "Final Answer:" in content:
        final_ans = content.split("Final Answer:")[-1].strip()

        # âœ… ä½¿ç”¨å¢å¼ºçš„åæ€æ£€æŸ¥
        needs_reflexion, reason = enhanced_reflexion_check(
            question=user_query,
            answer=final_ans,
            evidence_list=collected_evidence,  # éœ€è¦åœ¨æ¨ç†è¿‡ç¨‹ä¸­æ”¶é›†
            reflexion_count=state.get("reflexion_count", 0)
        )

        if needs_reflexion:
            logger.warning(f"Reflexion triggered: {reason}")

            # ç”Ÿæˆé’ˆå¯¹æ€§çš„æŒ‡å¯¼
            guidance = generate_reflexion_guidance(reason, user_query)

            state["messages"].append({
                "role": "user",
                "content": f"Reflexion: {reason}\n\n{guidance}"
            })
            state["reflexion_count"] = state.get("reflexion_count", 0) + 1
            continue

def generate_reflexion_guidance(reason: str, question: str) -> str:
    """æ ¹æ®åæ€åŸå› ç”Ÿæˆå…·ä½“æŒ‡å¯¼"""

    if "è¯æ®æ¥æºä¸è¶³" in reason:
        return (
            "å»ºè®®è¡ŒåŠ¨:\n"
            "1. ä½¿ç”¨ multi_strategy_search ä»ä¸åŒè§’åº¦æœç´¢\n"
            "2. ä½¿ç”¨ web_fetch è¯»å–è‡³å°‘2ä¸ªæƒå¨æ¥æº(.edu/.gov)\n"
            "3. å¯¹æ¯”ä¸åŒæ¥æºçš„ä¿¡æ¯,ç¡®è®¤ä¸€è‡´æ€§"
        )

    elif "å¹´ä»½" in reason or "æ•°å­—" in reason:
        return (
            "å»ºè®®è¡ŒåŠ¨:\n"
            "1. é‡æ–°æœç´¢,å…³é”®è¯ä¸­æ˜ç¡®åŒ…å«'year'æˆ–'date'\n"
            "2. ä½¿ç”¨ web_fetch è¯»å–å®˜æ–¹æ—¶é—´çº¿æˆ–å†å²é¡µé¢\n"
            "3. äº¤å‰éªŒè¯ä¸åŒæ¥æºçš„å¹´ä»½ä¿¡æ¯"
        )

    elif "äººå" in reason:
        return (
            "å»ºè®®è¡ŒåŠ¨:\n"
            "1. æœç´¢ '[å®ä½“] founder/inventor/creator'\n"
            "2. æ£€æŸ¥ç»´åŸºç™¾ç§‘æˆ–å®˜æ–¹ç½‘ç«™çš„åˆ›å§‹äººä¿¡æ¯\n"
            "3. ç¡®è®¤äººåå…¨ç§°(First Name + Last Name)"
        )

    elif "ä¸ç¡®å®šæ€§" in reason:
        return (
            "å»ºè®®è¡ŒåŠ¨:\n"
            "1. å¯»æ‰¾æ›´æƒå¨çš„æ¥æº(é¿å…åšå®¢/ç¤¾äº¤åª’ä½“)\n"
            "2. ä½¿ç”¨ verify_answer_with_cov è¿›è¡ŒéªŒè¯é“¾æ£€æŸ¥\n"
            "3. å¦‚æœç¡®å®æ— æ³•ç¡®å®š,ç»§ç»­æœç´¢å…¶ä»–å…³é”®è¯"
        )

    else:
        return (
            "å»ºè®®è¡ŒåŠ¨:\n"
            "1. é‡æ–°å®¡è§†é—®é¢˜,ç¡®è®¤ç†è§£æ­£ç¡®\n"
            "2. æ”¹å˜æœç´¢ç­–ç•¥æˆ–å…³é”®è¯\n"
            "3. é˜…è¯»æ›´å¤šåŸæ–‡,è€Œéä»…ä¾èµ–æ‘˜è¦"
        )
```

**é¢„æœŸæ”¶ç›Š**:
- âœ… å‡å°‘ä½è´¨é‡ç­”æ¡ˆ **70%**
- âœ… è‡ªåŠ¨å‘ç°é€»è¾‘é”™è¯¯
- âœ… æä¾›é’ˆå¯¹æ€§æ”¹è¿›å»ºè®®

---

## ğŸ“Š æ•´ä½“æ¶æ„è°ƒæ•´

### å·¥å…·å‡½æ•°æ¸…å•(ä¼˜å…ˆçº§æ’åº)

**æ ¸å¿ƒå·¥å…·** (å¿…é¡»):
1. âœ… `extract_entities` - å®ä½“æå–
2. âœ… `multi_strategy_search` - **æ–°å¢** å¤šç­–ç•¥æœç´¢
3. âœ… `web_fetch` - ç½‘é¡µæŠ“å–
4. âœ… `browse_page` - LLMæµè§ˆç½‘é¡µ
5. âœ… `browse_pdf_attachment` - PDFæµè§ˆ

**é«˜çº§å·¥å…·** (æ¨è):
6. â­ `verify_answer_with_cov` - **æ–°å¢** ç­”æ¡ˆéªŒè¯é“¾
7. â­ `check_answer_consistency` - **æ–°å¢** è‡ªæ´½æ€§æ£€æŸ¥

**è¾…åŠ©å·¥å…·** (å¯é€‰):
8. `web_search` - ä¿ç•™ä½œä¸ºåŸºç¡€æœç´¢
9. `x_keyword_search` - Twitteræœç´¢
10. `search_pdf_attachment` - PDFå…³é”®è¯æœç´¢

### agent_loop æ¨ç†æµç¨‹è°ƒæ•´

```python
# agent_loop.py ä¼˜åŒ–åçš„ä¸»å¾ªç¯

async def agent_loop(question: str, session_id: str, max_steps: int = 20):
    """
    ä¼˜åŒ–åçš„Agentå¾ªç¯

    å…³é”®æ”¹è¿›:
    1. åŠ¨æ€è°ƒæ•´max_steps (10-25æ­¥,åŸºäºé—®é¢˜å¤æ‚åº¦)
    2. å¼ºåˆ¶å¤šæºéªŒè¯
    3. ä¸­æœŸæ£€æŸ¥ç‚¹(æ¯5æ­¥è¯„ä¼°è¿›å±•)
    4. æœ€ç»ˆç­”æ¡ˆå‰è¿è¡ŒéªŒè¯é“¾
    """

    # åˆ†æé—®é¢˜å¤æ‚åº¦,åŠ¨æ€è°ƒæ•´æ­¥æ•°
    max_steps = analyze_question_complexity(question)
    logger.info(f"Question complexity analysis: max_steps={max_steps}")

    # æ”¶é›†è¯æ®
    evidence_list = []

    for step in range(max_steps):
        # ... å·¥å…·è°ƒç”¨ ...

        # æ”¶é›†è¯æ®
        if msg.get("name") == "web_fetch":
            evidence_list.append(Evidence(...))

        # === ä¸­æœŸæ£€æŸ¥ç‚¹ ===
        if step > 0 and step % 5 == 0:
            progress_check = evaluate_progress(state, question)
            if progress_check["stuck"]:
                logger.warning("Progress stuck, injecting guidance")
                state["messages"].append({
                    "role": "system",
                    "content": progress_check["guidance"]
                })

        # ... Reflexionæ£€æŸ¥ ...

        if not state.get("had_tool_calls"):
            # ç”Ÿæˆå€™é€‰ç­”æ¡ˆ
            candidate_answer = extract_final_answer(state["messages"])

            # === æœ€ç»ˆéªŒè¯ ===
            if candidate_answer:
                # 1. å¤šæºéªŒè¯
                ver_result = verify_answer(question, candidate_answer, evidence_list)

                if not ver_result.is_verified and ver_result.confidence < 0.6:
                    logger.warning(f"Verification failed: confidence={ver_result.confidence}")
                    # è§¦å‘é‡æ–°æœç´¢
                    continue

                # 2. è‡ªæ´½æ€§æ£€æŸ¥ (å¯é€‰,é«˜ä»·å€¼é—®é¢˜)
                if is_high_value_question(question):
                    consistency_result = check_consistency(question, state["messages"])
                    if consistency_result["consistency_score"] < 0.7:
                        # ä½¿ç”¨æ›´ä¸€è‡´çš„ç­”æ¡ˆ
                        candidate_answer = consistency_result["most_consistent_answer"]

                # 3. éªŒè¯é“¾ (å¯é€‰)
                if ver_result.confidence < 0.8:
                    cov_result = verify_with_cov(question, candidate_answer)
                    candidate_answer = cov_result["verified_answer"]

            break

    # ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ
    return candidate_answer


def analyze_question_complexity(question: str) -> int:
    """åˆ†æé—®é¢˜å¤æ‚åº¦,è¿”å›å»ºè®®æ­¥æ•°"""
    base_steps = 15
    complexity = 0

    # é•¿é—®é¢˜ +5
    if len(question) > 100:
        complexity += 5

    # å¤šè·³æ¨ç†å…³é”®è¯ +5
    if any(kw in question for kw in ["ç„¶å", "ä¹‹å", "è¿›ä¸€æ­¥", "å½±å“"]):
        complexity += 5

    # éœ€è¦å¯¹æ¯” +3
    if any(kw in question for kw in ["åŒºåˆ«", "å¯¹æ¯”", "vs"]):
        complexity += 3

    # éœ€è¦æ—¶é—´çº¿ +3
    if any(kw in question for kw in ["å†å²", "å‘å±•", "timeline"]):
        complexity += 3

    return min(base_steps + complexity, 25)  # ä¸Šé™25æ­¥


def evaluate_progress(state: Dict, question: str) -> Dict:
    """è¯„ä¼°æ¨ç†è¿›å±•"""

    # ç»Ÿè®¡å·¥å…·è°ƒç”¨
    search_count = sum(1 for msg in state["messages"] if msg.get("name") == "web_search")
    fetch_count = sum(1 for msg in state["messages"] if msg.get("name") == "web_fetch")

    stuck = False
    guidance = ""

    # æ£€æµ‹å¡ä½çš„æ¨¡å¼
    if search_count > 5 and fetch_count == 0:
        stuck = True
        guidance = (
            "[Progress Check] æ£€æµ‹åˆ°ä»…æœç´¢æœªè¯»å–å…¨æ–‡ã€‚\n"
            "å»ºè®®: ä½¿ç”¨ web_fetch è¯»å–å‰3ä¸ªæœç´¢ç»“æœçš„å…¨æ–‡ã€‚"
        )

    elif search_count > 3 and all(
        "similar" in str(msg) for msg in state["messages"][-3:]
    ):
        stuck = True
        guidance = (
            "[Progress Check] æ£€æµ‹åˆ°é‡å¤æœç´¢ç›¸ä¼¼å…³é”®è¯ã€‚\n"
            "å»ºè®®: æ”¹å˜ç­–ç•¥,å°è¯•:\n"
            "1. åˆ‡æ¢è¯­è¨€(ä¸­æ–‡â†”è‹±æ–‡)\n"
            "2. ä½¿ç”¨ multi_strategy_search æ”¹å˜ç­–ç•¥\n"
            "3. æœç´¢ç›¸å…³å®ä½“è€Œéç›´æ¥é—®é¢˜"
        )

    return {
        "stuck": stuck,
        "guidance": guidance,
        "search_count": search_count,
        "fetch_count": fetch_count
    }
```

---

## ğŸ¯ å®æ–½ä¼˜å…ˆçº§

### Week 1: æœç´¢ç­–ç•¥å¢å¼º (æœ€é«˜ROI)
**é¢„æœŸæå‡**: å‡†ç¡®ç‡ +20-30%

- [ ] Day 1-2: å®ç° `search_strategies.py`
  - `SearchStrategyManager`
  - `SourceCredibilityScorer`
- [ ] Day 3: é›†æˆ `multi_strategy_search` å·¥å…·
- [ ] Day 4: æµ‹è¯•5-10ä¸ªçœŸå®é—®é¢˜,å¯¹æ¯”æ”¹è¿›å‰å
- [ ] Day 5: è°ƒä¼˜ç­–ç•¥å‚æ•°

### Week 2: éªŒè¯æœºåˆ¶ (å‡†ç¡®æ€§ä¿è¯)
**é¢„æœŸæå‡**: å‡†ç¡®ç‡ +15-25%

- [ ] Day 1-2: å®ç° `answer_verification.py`
  - `AnswerVerifier`
  - `Evidence` æ•°æ®ç»“æ„
- [ ] Day 3: é›†æˆåˆ° `agent_loop.py`
- [ ] Day 4: å®ç° Reflexion å¢å¼º
- [ ] Day 5: ç«¯åˆ°ç«¯æµ‹è¯•

### Week 3: æ·±åº¦æ¨ç† (å¤æ‚é—®é¢˜çªç ´)
**é¢„æœŸæå‡**: å¤æ‚é—®é¢˜å‡†ç¡®ç‡ +30%

- [ ] Day 1-2: å®ç° `cov_reasoning.py`
  - `ChainOfVerification`
  - `SelfConsistencyChecker`
- [ ] Day 3: é›†æˆ CoV å’Œè‡ªæ´½æ€§æ£€æŸ¥
- [ ] Day 4: ä¼˜åŒ– System Prompt å’Œ Few-Shot
- [ ] Day 5: å…¨é¢æµ‹è¯•,è°ƒä¼˜å‚æ•°

---

## âœ… éªŒè¯æ–¹æ³•

### å‡†ç¡®ç‡æµ‹è¯•é›†
å»ºè®®å‡†å¤‡50ä¸ªæ ‡å‡†é—®é¢˜,æ¶µç›–:
- äº‹å®æŸ¥è¯¢ (20é¢˜): "è°å‘æ˜äº†XX?"
- æ•°å­—æŸ¥è¯¢ (10é¢˜): "XXå‘ç”Ÿåœ¨å“ªä¸€å¹´?"
- å¯¹æ¯”åˆ†æ (10é¢˜): "XXå’ŒYYçš„åŒºåˆ«?"
- å¤æ‚æ¨ç† (10é¢˜): "XXçš„å‘æ˜å¯¹YYäº§ç”Ÿäº†ä»€ä¹ˆå½±å“?"

### è¯„ä¼°æŒ‡æ ‡
```python
{
    "accuracy": "å‡†ç¡®ç‡ (å®Œå…¨æ­£ç¡®ç­”æ¡ˆæ¯”ä¾‹)",
    "partial_accuracy": "éƒ¨åˆ†æ­£ç¡®ç‡ (åŒ…å«æ­£ç¡®ä¿¡æ¯ä½†ä¸å®Œæ•´)",
    "verification_rate": "å¤šæºéªŒè¯ç‡ (ä½¿ç”¨â‰¥2ä¸ªæ¥æºçš„æ¯”ä¾‹)",
    "avg_steps": "å¹³å‡æ¨ç†æ­¥æ•°",
    "avg_time": "å¹³å‡è€—æ—¶ (ç§’)",
    "reflexion_trigger_rate": "åæ€è§¦å‘ç‡"
}
```

### å¯¹æ¯”åŸºå‡†
- **ä¼˜åŒ–å‰**: åœ¨æµ‹è¯•é›†ä¸Šè¿è¡Œ,è®°å½•åŸºå‡†æŒ‡æ ‡
- **ä¼˜åŒ–å**: æ¯ä¸ªPhaseå®Œæˆåé‡æ–°æµ‹è¯•
- **ç›®æ ‡**: å‡†ç¡®ç‡ä» 60-70% æå‡åˆ° 85-95%

---

## ğŸ“Œ å…³é”®æˆåŠŸå› ç´ 

### 1. è¯æ®è´¨é‡ \u003e è¯æ®æ•°é‡
- 1ä¸ªæƒå¨æ¥æº \u003e 5ä¸ªåšå®¢
- .edu/.gov \u003e ç¤¾äº¤åª’ä½“

### 2. æ·±åº¦é˜…è¯» \u003e å¹¿åº¦æœç´¢
- è¯»3ä¸ªå…¨æ–‡ \u003e æœ10æ¬¡åªçœ‹æ‘˜è¦

### 3. éªŒè¯ \u003e é€Ÿåº¦
- å®å¯å¤šèŠ±2-3æ­¥éªŒè¯,ä¹Ÿä¸è¦å¿«é€Ÿè¾“å‡ºé”™è¯¯ç­”æ¡ˆ

### 4. ç­–ç•¥å¤šæ ·æ€§
- åŒä¸€é—®é¢˜å°è¯•3ç§ä¸åŒæœç´¢ç­–ç•¥
- ä¸­è‹±æ–‡äº¤å‰éªŒè¯

---

## ğŸ‰ é¢„æœŸæœ€ç»ˆæ•ˆæœ

| ç»´åº¦ | ä¼˜åŒ–å‰ | ä¼˜åŒ–å | æå‡ |
|------|--------|--------|------|
| **å‡†ç¡®ç‡** | 60-70% | **85-95%** | +25-35% â­ |
| **å¤šæºéªŒè¯ç‡** | \u003c20% | **\u003e80%** | +60% |
| **æœç´¢åç¦»ç‡** | ~30% | **\u003c5%** | -25% |
| **å¹³å‡æ­¥æ•°** | 8-12æ­¥ | 10-18æ­¥ | +2-6æ­¥ |
| **å¹³å‡è€—æ—¶** | 3-5åˆ†é’Ÿ | 4-8åˆ†é’Ÿ | å¯æ¥å—èŒƒå›´å†… âœ… |
| **å¤æ‚é—®é¢˜æˆåŠŸç‡** | 40% | **75%** | +35% â­ |

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0
**æœ€åæ›´æ–°**: 2026-02-03
**é€‚ç”¨åœºæ™¯**: å¤©æ± ç®—æ³•å¤§èµ›ã€å¤æ‚çŸ¥è¯†é—®ç­”ã€ç ”ç©¶å‹ä»»åŠ¡
