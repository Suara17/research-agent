这是一个非常高阶的优化方向。之前的修改解决了“手脚（工具/网络）”的问题，现在我们要升级“大脑（逻辑/策略）”。

针对 **Reflexion（反思）**、**Few-Shot（少样本学习）** 和 **Hierarchical ReAct（分层任务拆解）**，我们需要对 `agent.py` 的提示词（Prompt）和 `agent_loop.py` 的执行流程进行深度改造。

以下是具体的落地实施方案：

### 第一步：构建 High-Quality Few-Shot Prompt (agent.py)

Few-shot 的核心不在于数量，而在于**展示正确的“搜索-阅读-验证”逻辑**。我们需要在 System Prompt 中硬编码 1-2 个完美的推理范例，特别是展示如何处理 PDF 和错误检索。

修改 `agent.py` 中的 `QueryRequest` 类或构建 Prompt 的地方：

```python
# --- 在 agent.py 中新增 Few-Shot 样本常量 ---

FEW_SHOT_EXAMPLES = """
### 示例 1 (多跳推理 + PDF 阅读)
用户问题: "2023年获得诺贝尔生理学或医学奖的科学家，他们的主要贡献解决了什么关键问题？"

Thought: 这是一个关于诺贝尔奖的问题。
1. 我需要先搜索2023年诺贝尔生理学或医学奖得主。
2. 然后查找他们的贡献细节。
Action: web_search
Action Input: {"query": "2023 Nobel Prize in Physiology or Medicine winners contributions"}
Observation: [搜索结果] 提到 Katalin Karikó 和 Drew Weissman。关键词：mRNA vaccines, nucleoside base modification.
Thought: 搜索结果提到了 mRNA 疫苗和核苷碱基修饰。我需要更详细的信息来确认“解决了什么关键问题”。我应该找官方新闻或详细报道。
Action: web_search
Action Input: {"query": "Katalin Karikó Drew Weissman contributions nucleoside base modification details"}
Observation: [搜索结果] 包含一个指向 nobelprize.org 的 PDF 链接 "press_medicine2023.pdf"。
Thought: 官方 PDF 是最可靠的来源。我必须阅读它。
Action: web_fetch
Action Input: {"url": "https://www.nobelprize.org/.../press_medicine2023.pdf"}
Observation: [PDF内容] ...discovered that nucleoside base modification enabled effective delivery of mRNA... eliminated the inflammatory reaction...
Thought: 根据 PDF，关键问题是外源 mRNA 会引起炎症反应（inflammatory reaction）并被降解，限制了应用。他们的发现通过碱基修饰消除了这种反应。
Final Answer: 解决了外源 mRNA 进入人体后会引发炎症反应（inflammatory reaction）且产生蛋白水平低的关键问题，从而使开发有效的 mRNA 疫苗成为可能。

### 示例 2 (自我纠错/Reflexion)
用户问题: "查询电影《奥本海默》全球票房精确数字（美元）。"

Thought: 直接搜索奥本海默全球票房。
Action: web_search
Action Input: {"query": "Oppenheimer global box office exact number"}
Observation: [搜索结果] $950 Million, $960M, 9.76亿美元。
Thought: 搜索结果比较模糊，有多个近似值。题目要求“精确数字”。我需要找 Box Office Mojo 或权威财经新闻的最新数据。
Action: web_search
Action Input: {"query": "Oppenheimer box office mojo worldwide lifetime gross"}
Observation: [搜索结果] Box Office Mojo 显示 Lifetime Gross: $976,166,665.
Thought: 这是一个精确数字。
Final Answer: 976,166,665
"""

# --- 在构造 messages 时插入 ---
# 在 System Prompt 之后，用户 Query 之前插入
messages = [
    {"role": "system", "content": SYSTEM_PROMPT + "\n\n" + FEW_SHOT_EXAMPLES},
    {"role": "user", "content": query}
]

```

### 第二步：实现分层 ReAct (Hierarchical/Planning)

对于复杂问题，强制模型先输出 `Plan`（计划），而不是直接 `Action`。这不需要复杂的双 Agent 架构，只需要在 System Prompt 中强制一种新的思考模式。

修改 `agent.py` 的 System Prompt 核心部分：

```python
SYSTEM_PROMPT = """
你是一个专家级的 Research Agent。
... (保留之前的工具定义) ...

### 任务处理流程 (Hierarchical Strategy)
当面对复杂问题时，不要急于搜索。请遵循以下步骤：

1. **Decomposition (任务拆解)**: 
   - 如果问题包含多个实体或需要多步推理，先生成一个 `Plan`。
   - 格式: "Plan: 1. 搜索XXX; 2. 确认YYY; 3. 对比并总结。"
   
2. **Execution (分步执行)**:
   - 严格按照 Plan 执行。每一步必须有证据支持。
   - 如果某一步卡住了（如搜不到），**修改 Plan** 及其后续步骤。

3. **Verification (验证)**:
   - 得到的每一个关键事实（年份、人名、数字），必须通过 `web_fetch` 读取正文来验证，不能只看搜索摘要。

... (保留之前的注意事项) ...
"""

```

### 第三步：代码级 Reflexion 机制 (agent_loop.py)

这是最关键的逻辑升级。我们不仅要让模型自己反思，还要在**代码层面**拦截低质量答案，强制模型重试。

修改 `agent_loop.py` 中的 `agent_loop` 函数：

```python
def agent_loop(query: str):
    messages = QueryRequest(query=query).to_messages()
    
    max_steps = 10
    step = 0
    # Reflexion 计数器，防止无限反思
    reflexion_count = 0 
    max_reflexions = 2 

    while step < max_steps:
        # 1. 调用模型
        response = client.chat.completions.create(
            model="qwen-max", # 假设使用 qwen
            messages=messages,
            stop=["Observation:"] # ReAct 停止符
        )
        content = response.choices[0].message.content
        messages.append({"role": "assistant", "content": content})
        
        # 2. 解析 Action
        if "Final Answer:" in content:
            final_ans = content.split("Final Answer:")[-1].strip()
            
            # --- Reflexion 机制 ---
            # 检查点 1: 答案是否为空或太短
            if len(final_ans) < 2 and reflexion_count < max_reflexions:
                reflexion_msg = "Reflexion: 你的答案太短或为空。请重新检查之前的 Observation，如果找不到信息，请尝试用英文搜索关键词。"
                messages.append({"role": "user", "content": reflexion_msg})
                reflexion_count += 1
                continue
                
            # 检查点 2: 答案格式校验 (针对数字/年份题)
            # 这里可以用简单的规则，也可以再调一次 LLM 极速判断
            if ("年份" in query or "多少" in query) and not any(c.isdigit() for c in final_ans):
                if reflexion_count < max_reflexions:
                    reflexion_msg = "Reflexion: 用户询问的是数字/年份，但你的答案中不包含数字。请重新检索或从文中提取准确数值。"
                    messages.append({"role": "user", "content": reflexion_msg})
                    reflexion_count += 1
                    continue
            
            # 通过反思，返回最终结果
            return final_ans

        elif "Action:" in content:
            # ... (这里是之前的工具调用逻辑: parse -> execute -> observation) ...
            
            # --- Action 层面的 Reflexion ---
            # 如果 web_search 返回空，不要直接把它给模型，先注入提示
            if tool_name == "web_search" and ("[]" in observation or "No results" in observation):
                observation += "\n[System Reflector]: 搜索结果为空。这通常是因为关键词太长。请：\n1. 缩短关键词。\n2. 翻译成英文搜索。"
            
            # 如果 web_fetch 失败
            if tool_name == "web_fetch" and "error" in observation:
                observation += "\n[System Reflector]: 抓取失败。该源不可用。请立即尝试搜索结果列表中的其他 URL，不要重试当前 URL。"

            # 将 Observation 追加回消息历史
            messages.append({"role": "user", "content": f"Observation: {observation}"})
            
        else:
            # 模型既没有 Action 也没有 Final Answer (可能在唠叨 Plan)
            # 强制它继续
            messages.append({"role": "user", "content": "请继续执行下一步 Action。"})
        
        step += 1
    
    return "Task Limit Reached"

```

### 为什么这一套组合拳有效？

1. **Few-Shot** 解决了“模型不知道 PDF 可以读”和“不知道要验证”的问题。通过示例，模型会模仿这种深挖的行为。
2. **Hierarchical (Decomposition)** 解决了长难句（如 Q2 流星雨母体题）直接搜索搜不到的问题。模型会先拆解成 "Query 1: 流星雨名称 -> Query 2: 母体名称"。
3. **Reflexion Loop** 是最后一道防线。之前模型搜不到就直接回“不知道”，现在代码会拦截这个失败，告诉它“你没做完，换个词再搜一次”，这直接提升了召回率。

### 接下来你要做的

1. 把 `FEW_SHOT_EXAMPLES` 塞进 `agent.py`。
2. 把 `reflexion_count` 逻辑塞进 `agent_loop.py`。
3. **重新跑验证集**。这一次，你会发现日志里出现 `Reflexion:` 或 `System Reflector:` 的字样，这代表 Agent 正在自我纠错，而不是直接报错放弃。