针对 `smart-search` 技能的优化方案，核心在于**从“基于规则的关键词拼接”进化为“基于 LLM 的结构化查询生成”**。

之前的版本严重依赖正则（Regex）提取实体，这在处理复杂语义（如“因亲属财产风波受挫”）时容易产生碎片化关键词，导致搜索引擎返回无关结果。

以下是具体的优化修改方案：

### 优化思路

1. **引入结构化分析 (Structured Analysis)**：不再只提取碎片关键词，而是让 LLM 分析查询的**意图 (Intent)**、**核心实体 (Core Entities)** 和 **必须包含的约束 (Constraints)**，并返回 JSON。
2. **强制“列表”策略 (List-Generation Strategy)**：针对 "Who is the person..." 这类问题，自动生成 "List of candidates..." 查询，解决“过早收敛”问题。
3. **原生多语言构造 (Native Multi-lingual)**：由 LLM 直接生成英文和目标语言（如蒙文、法文等）的查询，而不是在 Python 里硬编码。
4. **降级保护**：如果 LLM 调用失败，回退到原有的正则逻辑。

---

### 1. 修改 `run.py`

这个版本引入了更强的 LLM 解析逻辑，直接输出优化好的 Query List。

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Smart Search Skill v3 - 结构化意图分析与列表生成增强版
"""

import os
import json
import sys
import re
from openai import OpenAI

def _load_env():
    """加载 .env 文件"""
    try:
        paths = [
            os.path.join(os.getcwd(), ".env"),
            os.path.join(os.path.dirname(os.path.abspath(__file__)), ".env"),
            os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))), ".env")
        ]
        for p in paths:
            if os.path.exists(p):
                with open(p, "r", encoding="utf-8") as f:
                    for line in f:
                        line = line.strip()
                        if not line or line.startswith("#") or "=" not in line:
                            continue
                        k, v = line.split("=", 1)
                        if k not in os.environ:
                            os.environ[k.strip()] = v.strip().strip("'").strip('"')
    except Exception:
        pass

def _get_client():
    api_key = os.environ.get("IFLOW_API_KEY")
    if not api_key:
        return None
    return OpenAI(base_url="https://apis.iflow.cn/v1", api_key=api_key, timeout=15.0)

def _analyze_query_with_llm(query: str, original_entities: list) -> dict:
    """
    使用 LLM 进行结构化查询分析
    返回: {
        "intent": "person_search" | "fact_check" | "list_generation" | "riddle",
        "keywords_en": ["keyword1", "keyword2"],
        "keywords_native": ["关键词1", "关键词2"],
        "search_queries": ["query1", "query2"]
    }
    """
    client = _get_client()
    if not client:
        return None

    # Prompt 设计重点：强制生成"列表型"查询，以及分离硬约束
    prompt = f"""You are a Search Engine Optimization Expert.
Analyze the user query and generate diverse search queries.

User Query: "{query}"
Known Entities: {json.dumps(original_entities, ensure_ascii=False)}

Analysis Tasks:
1. **Identify Intent**: Is it looking for a specific person, checking a fact, or solving a riddle?
2. **Extract Constraints**: Separate "Hard Constraints" (Dates, Locations) from "Soft Descriptions".
3. **Cross-Lingual**: If the topic implies a non-English country (e.g., Mongolia, Japan), generate queries in English AND that specific language context.
4. **List Strategy**: If the user asks "Who is...", generate a "List of..." query first (e.g., "List of Prime Ministers of Mongolia 2010-2020").

Output JSON format ONLY:
{{
    "intent": "string",
    "primary_language_of_topic": "string (e.g., English, Chinese, Mongolian)",
    "extracted_keywords": ["str"],
    "generated_queries": [
        "precise keyword query",
        "list generation query (if applicable)",
        "cross-lingual query (if applicable)",
        "site:wikipedia.org query"
    ]
}}
"""
    try:
        response = client.chat.completions.create(
            model="qwen3-max",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.2,
            response_format={"type": "json_object"},
            max_tokens=512
        )
        content = response.choices[0].message.content
        return json.loads(content)
    except Exception as e:
        print(f"DEBUG: LLM Analysis failed: {e}", file=sys.stderr)
        return None

def _fallback_keyword_extraction(text: str) -> list:
    """正则兜底提取逻辑 (原 _extract_keywords 的简化版)"""
    stopwords = {'what', 'who', 'find', 'search', 'question', 'answer', 'the', 'a', 'in', 'of', 'and'}
    words = re.findall(r'[\u4e00-\u9fff]{2,}|[a-zA-Z0-9]+', text)
    return [w for w in words if w.lower() not in stopwords and not (w.isdigit() and len(w)<4)]

def main():
    try:
        _load_env()
        # 参数解析逻辑保持不变
        args_file = os.environ.get("SKILL_ARGS_FILE")
        if args_file and os.path.exists(args_file):
            with open(args_file, 'r', encoding='utf-8') as f:
                args = json.load(f)
        else:
            args_json = os.environ.get("SKILL_ARGS", "{}")
            args = json.loads(args_json) if isinstance(args_json, str) else args_json

        if isinstance(args, str):
            try: args = json.loads(args)
            except: pass
        
        query = args.get("query", "")
        entities = args.get("entities", [])
        strategy = args.get("strategy", "auto")

        if not query:
            print(json.dumps({"error": "No query provided"}))
            sys.exit(1)

        # 1. 尝试 LLM 结构化分析 (优先)
        llm_result = _analyze_query_with_llm(query, entities)
        
        final_queries = []
        keywords = []
        
        if llm_result:
            # 使用 LLM 生成的高质量查询
            final_queries = llm_result.get("generated_queries", [])
            keywords = llm_result.get("extracted_keywords", [])
            
            # 策略补丁：如果 LLM 没有生成 wiki 查询，手动补一个
            has_site = any("site:" in q for q in final_queries)
            if not has_site:
                base_kw = " ".join(keywords[:5])
                final_queries.append(f'{base_kw} site:wikipedia.org OR site:baike.baidu.com')
                
        else:
            # 2. 降级回退：基于规则的生成 (原逻辑的精简版)
            keywords = _fallback_keyword_extraction(query)
            base_search = " ".join(keywords[:8])
            
            final_queries.append(base_search) # 基础查询
            final_queries.append(f"{base_search} wikipedia") # 百科查询
            
            # 简单的规则补充
            if "who" in query.lower() or "list" in query.lower():
                final_queries.append(f"List of {base_search}")
            if any(k in query.lower() for k in ['year', 'when', 'date']):
                final_queries.append(f"{base_search} timeline")

        # 3. 结果去重与清洗
        unique_queries = []
        seen = set()
        for q in final_queries:
            q_clean = re.sub(r'\s+', ' ', q).strip()
            if q_clean and q_clean.lower() not in seen:
                seen.add(q_clean.lower())
                unique_queries.append(q_clean)

        result = {
            "status": "success",
            "strategy_used": llm_result.get("intent", "fallback") if llm_result else "regex_fallback",
            "original_query": query,
            "optimized_queries": unique_queries[:5], # 限制返回数量
            "tips": "已利用 LLM 分析意图并生成结构化查询。" if llm_result else "LLM 分析超时，使用基础关键词查询。"
        }
        print(json.dumps(result, ensure_ascii=False, indent=2))

    except Exception as e:
        print(json.dumps({"error": str(e), "status": "failed"}), file=sys.stdout)
        sys.exit(1)

if __name__ == "__main__":
    main()

```

---

### 2. 修改 `SKILL.md`

更新文档以反映新的能力，特别是强调它如何帮助 Agent 避免“过早收敛”。

```markdown
---
name: smart-search
description: 智能搜索构建器。利用 LLM 将自然语言问题转化为多个高精度的搜索引擎查询（Query）。支持意图识别、列表生成（防止过早收敛）、跨语言关键词提取和特定站点（Wiki/Edu）过滤。
---

# Smart Search Skill (v3 结构化版)

## 核心价值
本工具解决了 Agent "直接搜整句搜不到" 和 "搜到错误答案（过早收敛）" 的痛点。
它**不执行搜索**，而是**生成最好的搜索词**供你使用。

## 适用场景

1.  **列表-筛选模式 (List-then-Filter)** [最重要]
    * *问题*: "谁是蒙古国那个因亲属财产出丑闻的总理？"
    * *旧做法*: 直接搜整句 -> 搜出奥云额尔登（热门但错误）。
    * *新能力*: 工具会自动生成 `List of Prime Ministers of Mongolia`。
    * *Agent动作*: 你拿到这个 Query 后，去搜列表，然后一个个查，就能找到巴特包勒德。

2.  **谜语型/长难句 (Complex Riddle)**
    * *问题*: "一个20世纪90年代生效宪法并在2019年修宪的国家的元首..."
    * *新能力*: 提取结构化关键词 `Constitution 1990s effective` AND `2019 amendment` AND `Head of State`。

3.  **跨语言检索 (Cross-Lingual)**
    * *问题*: (中文) "...该实体的英文名称是什么？"
    * *新能力*: 自动翻译关键词并生成 `[Keywords] English Name` 或 `site:en.wikipedia.org` 查询。

## 使用指南 (Agent Prompt)

**何时调用？**
* 当用户问题超过 20 个字时。
* 当你尝试搜索一次但没有找到明确答案时。
* 当问题包含 "哪一年", "谁是", "列出" 等明确意图时。

**输入参数:**
* `query` (必填): 用户的原始自然语言问题，或者你推理出的中间问题。
* `entities` (选填): 你已经确认的实体（如 "蒙古国"），这能帮助工具生成更准的 Query。

**如何处理输出 (`optimized_queries`)?**
工具会返回一个列表，通常包含 3-5 个 Query。
1.  **优先执行列表型 Query** (如包含 "List of...", "Timeline of...")。
2.  **其次执行精确关键词 Query**。
3.  **最后执行宽泛的 Wiki Query**。

## 示例

**输入**:
```json
{
  "query": "一位曾在海外知名学府深造的政府首脑，其政治生涯因亲属财产风波受挫...",
  "entities": ["政府首脑", "亲属财产"]
}

```

**输出 (Example)**:

```json
{
  "status": "success",
  "optimized_queries": [
    "List of Heads of Government studied abroad scandal",  // 列表策略
    "Prime Minister relatives assets scandal offshore",   // 精确关键词
    "Government leader corruption mining investigation",  // 补充线索
    "site:wikipedia.org Head of Government scandal"       // 百科兜底
  ]
}

```

```

### 优化点总结

1.  **移除硬编码策略**：删除了 `_auto_select_strategy` 里那些 `if "movie" in query` 的硬编码判断，完全交给 LLM 判断意图。这更灵活，能处理意想不到的查询类型。
2.  **Prompt Engineering**：在 `_analyze_query_with_llm` 的 Prompt 中，明确指示 LLM 生成 "List Strategy" 查询。这直接回应了之前日志中“找不到巴特包勒德”的问题——因为没有先列出所有总理。
3.  **JSON Mode**：强制 LLM 输出 JSON，避免了 regex 解析的不稳定性。
4.  **容错性**：保留了 `_fallback_keyword_extraction`，万一 LLM API 挂了，Agent 至少还能进行基础的关键词搜索，不会 Crash。

```