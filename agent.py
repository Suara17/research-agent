import os
import json
from typing import Optional, List
from fastapi import FastAPI
from fastapi.responses import StreamingResponse
from pydantic import BaseModel, ConfigDict

# Import from package
from research_agent import config
from research_agent import (
    agent_loop,
    web_search,
    web_fetch,
    browse_page,
    x_keyword_search,
    search_pdf_attachment,
    browse_pdf_attachment,
    multi_hop_search,
    get_weather,
    extract_entities,
    check_answer_type,
    verify_answer,
    force_fix_answer,
    clean_answer,
    CandidatePool
)
from research_agent.complexity import calculate_max_steps

try:
    from agui import stream_agui_events, to_openai_messages, to_sse_data
    from ag_ui.core import RunAgentInput
    _AGUI_AVAILABLE = True
except Exception:
    _AGUI_AVAILABLE = False

app = FastAPI()

FEW_SHOT_EXAMPLES = """
### ç¤ºä¾‹ 1 (å¤šè·³æ¨ç† + PDF é˜…è¯»)
ç”¨æˆ·é—®é¢˜: "2023å¹´è·å¾—è¯ºè´å°”ç”Ÿç†å­¦æˆ–åŒ»å­¦å¥–çš„ç§‘å­¦å®¶ï¼Œä»–ä»¬çš„ä¸»è¦è´¡çŒ®è§£å†³äº†ä»€ä¹ˆå…³é”®é—®é¢˜ï¼Ÿ"

Thought: è¿™æ˜¯ä¸€ä¸ªå…³äºè¯ºè´å°”å¥–çš„é—®é¢˜ã€‚
1. æˆ‘éœ€è¦å…ˆæœç´¢2023å¹´è¯ºè´å°”ç”Ÿç†å­¦æˆ–åŒ»å­¦å¥–å¾—ä¸»ã€‚
2. ç„¶åæŸ¥æ‰¾ä»–ä»¬çš„è´¡çŒ®ç»†èŠ‚ã€‚
Action: web_search
Action Input: {"query": "2023 Nobel Prize in Physiology or Medicine winners contributions"}
Observation: [æœç´¢ç»“æœ] æåˆ° Katalin KarikÃ³ å’Œ Drew Weissmanã€‚å…³é”®è¯ï¼šmRNA vaccines, nucleoside base modification.
Thought: æœç´¢ç»“æœæåˆ°äº† mRNA ç–«è‹—å’Œæ ¸è‹·ç¢±åŸºä¿®é¥°ã€‚æˆ‘éœ€è¦æ›´è¯¦ç»†çš„ä¿¡æ¯æ¥ç¡®è®¤â€œè§£å†³äº†ä»€ä¹ˆå…³é”®é—®é¢˜â€ã€‚æˆ‘åº”è¯¥æ‰¾å®˜æ–¹æ–°é—»æˆ–è¯¦ç»†æŠ¥é“ã€‚
Action: web_search
Action Input: {"query": "Katalin KarikÃ³ Drew Weissman contributions nucleoside base modification details"}
Observation: [æœç´¢ç»“æœ] åŒ…å«ä¸€ä¸ªæŒ‡å‘ nobelprize.org çš„ PDF é“¾æ¥ "press_medicine2023.pdf"ã€‚
Thought: å®˜æ–¹ PDF æ˜¯æœ€å¯é çš„æ¥æºã€‚æˆ‘å¿…é¡»é˜…è¯»å®ƒã€‚
Action: web_fetch
Action Input: {"url": "https://www.nobelprize.org/.../press_medicine2023.pdf"}
Observation: [PDFå†…å®¹] ...discovered that nucleoside base modification enabled effective delivery of mRNA... eliminated the inflammatory reaction...
Thought: æ ¹æ® PDFï¼Œå…³é”®é—®é¢˜æ˜¯å¤–æº mRNA ä¼šå¼•èµ·ç‚ç—‡ååº”ï¼ˆinflammatory reactionï¼‰å¹¶è¢«é™è§£ï¼Œé™åˆ¶äº†åº”ç”¨ã€‚ä»–ä»¬çš„å‘ç°é€šè¿‡ç¢±åŸºä¿®é¥°æ¶ˆé™¤äº†è¿™ç§ååº”ã€‚
Final Answer: è§£å†³äº†å¤–æº mRNA è¿›å…¥äººä½“åä¼šå¼•å‘ç‚ç—‡ååº”ï¼ˆinflammatory reactionï¼‰ä¸”äº§ç”Ÿè›‹ç™½æ°´å¹³ä½çš„å…³é”®é—®é¢˜ï¼Œä»è€Œä½¿å¼€å‘æœ‰æ•ˆçš„ mRNA ç–«è‹—æˆä¸ºå¯èƒ½ã€‚

### ç¤ºä¾‹ 2 (è‡ªæˆ‘çº é”™/Reflexion)
ç”¨æˆ·é—®é¢˜: "æŸ¥è¯¢ç”µå½±ã€Šå¥¥æœ¬æµ·é»˜ã€‹å…¨çƒç¥¨æˆ¿ç²¾ç¡®æ•°å­—ï¼ˆç¾å…ƒï¼‰ã€‚"

Thought: ç›´æ¥æœç´¢å¥¥æœ¬æµ·é»˜å…¨çƒç¥¨æˆ¿ã€‚
Action: web_search
Action Input: {"query": "Oppenheimer global box office exact number"}
Observation: [æœç´¢ç»“æœ] $950 Million, $960M, 9.76äº¿ç¾å…ƒã€‚
Thought: æœç´¢ç»“æœæ¯”è¾ƒæ¨¡ç³Šï¼Œæœ‰å¤šä¸ªè¿‘ä¼¼å€¼ã€‚é¢˜ç›®è¦æ±‚â€œç²¾ç¡®æ•°å­—â€ã€‚æˆ‘éœ€è¦æ‰¾ Box Office Mojo æˆ–æƒå¨è´¢ç»æ–°é—»çš„æœ€æ–°æ•°æ®ã€‚
Action: web_search
Action Input: {"query": "Oppenheimer box office mojo worldwide lifetime gross"}
Observation: [æœç´¢ç»“æœ] Box Office Mojo æ˜¾ç¤º Lifetime Gross: $976,166,665.
Thought: è¿™æ˜¯ä¸€ä¸ªç²¾ç¡®æ•°å­—ã€‚
Final Answer: 976,166,665
"""

class QueryRequest(BaseModel):
    model_config = ConfigDict(
        extra="allow",
        json_schema_extra={
            "example": {"question": "What is the weather in Beijing today?"}
        },
    )

    question: str
    chat_history: Optional[list] = None

    def to_messages(self) -> list:
        if self.chat_history:
            return self.chat_history + [{"role": "user", "content": self.question}]
        else:
            return [
                {
                    "role": "system",
                    "content": (
                        """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ Research Agentã€‚ä½ çš„å”¯ä¸€ç›®æ ‡æ˜¯ç»™å‡ºç²¾å‡†çš„äº‹å®æ€§ç­”æ¡ˆã€‚

### æ ¸å¿ƒåŸåˆ™
1. **è¯æ®é©±åŠ¨**: æ¯ä¸ªç»“è®ºå¿…é¡»æœ‰æ˜ç¡®è¯æ®ï¼Œæ ‡æ³¨æ¥æºURL
2. **å¤šæºéªŒè¯**: å…³é”®ä¿¡æ¯ï¼ˆäººå/æ—¥æœŸ/æ•°å­—ï¼‰éœ€â‰¥2ä¸ªç‹¬ç«‹æ¥æºç¡®è®¤
3. **æ·±åº¦ä¼˜å…ˆ**: ä¼˜å…ˆä½¿ç”¨ web_fetch è¯»å–å…¨æ–‡ï¼Œè€Œéä¾èµ–æœç´¢æ‘˜è¦
4. **å–„ç”¨ Skills**: å¤æ‚ä»»åŠ¡ä½¿ç”¨ä¸“é—¨çš„ Skills æå‡å‡†ç¡®æ€§
5. **è¯­è¨€ä¸€è‡´æ€§**: ç­”æ¡ˆè¯­è¨€å¿…é¡»ä¸é—®é¢˜è¯­è¨€ä¿æŒä¸€è‡´ï¼ˆä¸­æ–‡é—®é¢˜ç”¨ä¸­æ–‡å›ç­”ï¼Œè‹±æ–‡é—®é¢˜ç”¨è‹±æ–‡å›ç­”ï¼‰ï¼Œé™¤éé—®é¢˜æ˜ç¡®è¦æ±‚ç‰¹å®šè¯­è¨€ã€‚

### å¯ç”¨ Skills
- **smart-search**: æ™ºèƒ½å¤šç­–ç•¥æœç´¢ï¼Œæ ¹æ®é—®é¢˜ç±»å‹è‡ªåŠ¨é€‰æ‹©æœ€ä½³æœç´¢ç­–ç•¥ï¼ˆå­¦æœ¯/æ–°é—»/æ—¶é—´çº¿/å¯¹æ¯”/å®šä¹‰ï¼‰ã€‚åˆæ¬¡æœç´¢æˆ–éœ€è¦æ”¹å˜ç­–ç•¥æ—¶ä½¿ç”¨ã€‚
- **multi-source-verify**: å¤šæºéªŒè¯ç­”æ¡ˆå‡†ç¡®æ€§ã€‚éªŒè¯å…³é”®äº‹å®ï¼ˆäººå/æ—¥æœŸ/æ•°å­—ï¼‰æ—¶ä½¿ç”¨ï¼Œè¦æ±‚è‡³å°‘2ä¸ªç‹¬ç«‹æ¥æºæ”¯æŒã€‚
- **chain-of-verification**: éªŒè¯é“¾æ¨ç†ã€‚å¯¹å¤æ‚æˆ–é«˜ä»·å€¼é—®é¢˜ï¼Œç”ŸæˆéªŒè¯é—®é¢˜å¹¶ç‹¬ç«‹æœç´¢éªŒè¯ï¼Œä¿®æ­£ç­”æ¡ˆã€‚å½“ç½®ä¿¡åº¦<0.8æ—¶ä½¿ç”¨ã€‚
- **deep-research**: æ·±åº¦ç ”ç©¶ã€‚éœ€è¦å¤šæ­¥æ·±åº¦ç ”ç©¶å’Œè¯æ®ç»¼åˆæ—¶ä½¿ç”¨ã€‚

### å¤šè·³æ¨ç†ç­–ç•¥ï¼ˆæ¼æ–—å¼æœç´¢æ³•ï¼‰
é¢å¯¹åŒ…å«å¤šä¸ªæ¡ä»¶çš„å¤æ‚é—®é¢˜ï¼Œé‡‡ç”¨ä»¥ä¸‹å››æ­¥æ³•ï¼š

**æ­¥éª¤1 - æ‹†è§£ä¸æå–ï¼ˆè¯†åˆ«é”šç‚¹ï¼‰**
- ä¸è¦æœç´¢æ•´å¥è¯ï¼Œè€Œæ˜¯è¯†åˆ«æœ€å…·ä½“çš„"é”šç‚¹"å…³é”®è¯
- ä½ä»·å€¼è¯ç¤ºä¾‹ï¼ˆå¤ªå®½æ³›ï¼‰ï¼š"æ—¥æœ¬å…¬å¸"ã€"20ä¸–çºª"ã€"çŸ¥åæ¸¸æˆ"
- é«˜ä»·å€¼è¯ç¤ºä¾‹ï¼ˆé”šç‚¹ï¼‰ï¼š"æ”¹ç¼–åŠ¨ç”»ç‰‡"ã€"åŠ¨ä½œæ¸¸æˆç³»åˆ—"ã€å…·ä½“ä½œå“å

**æ­¥éª¤2 - é€æ­¥æ”¶æ•›ï¼ˆæ¼æ–—æœç´¢ï¼‰**
- ç¬¬ä¸€æ­¥ï¼šç¡®å®šå®ä½“ï¼ˆåˆ©ç”¨"äº¤é›†"é€»è¾‘æ‰¾å”¯ä¸€è§£ï¼‰
  - æœç´¢é«˜ä»·å€¼é”šç‚¹è¯ç»„åˆ
  - ä»ç»“æœä¸­ç­›é€‰ç¬¦åˆçº¦æŸæ¡ä»¶çš„å€™é€‰é¡¹
- ç¬¬äºŒæ­¥ï¼šæŸ¥è¯¢å±æ€§ï¼ˆé’ˆå¯¹é”å®šå®ä½“ç²¾å‡†æŸ¥è¯¢ï¼‰
  - ä¸€æ—¦é”å®šç›®æ ‡å®ä½“ï¼Œå†æŸ¥å…·ä½“å±æ€§

**æ­¥éª¤3 - é«˜é˜¶æœç´¢æŒ‡ä»¤**
- å¼ºåˆ¶åŒ¹é…ï¼ˆå¼•å·ï¼‰ï¼š"animated series"
- ç«™å†…æœç´¢ï¼ˆsite:ï¼‰ï¼šsite:wikipedia.org
- æ’é™¤å¹²æ‰°ï¼ˆå‡å·ï¼‰ï¼š-Nintendo

**æ­¥éª¤4 - éªŒè¯ä¸ä¸‰è§’æµ‹é‡**
- å¯¹æ¨ç†å‡ºçš„ç­”æ¡ˆè¿›è¡Œ"å›æµ‹"ï¼Œç¡®ä¿ç¬¦åˆæ‰€æœ‰æè¿°æ¡ä»¶

### é»„é‡‘æ³•åˆ™
1. **æœç´¢æ‘˜è¦å¸¸é”™è¯¯**: å¿…é¡»ä½¿ç”¨ web_fetch è¯»å–å…¨æ–‡éªŒè¯ï¼Œä¸èƒ½åªçœ‹æ‘˜è¦
2. **PDFä¼˜å…ˆ**: å­¦æœ¯/å†å²/æ³•å¾‹é—®é¢˜ç­”æ¡ˆå¸¸åœ¨PDFä¸­ï¼Œä¼˜å…ˆä½¿ç”¨ browse_pdf_attachment
3. **æ‹†åˆ†å¤æ‚é—®é¢˜**: å¤æ‚é—®é¢˜æ‹†åˆ†ä¸ºå­é—®é¢˜ï¼Œé€æ­¥éªŒè¯ã€‚å¤šè·³é—®é¢˜å¿…é¡»ä½¿ç”¨æ¼æ–—æœç´¢æ³•
4. **æ­»å¾ªç¯æ£€æµ‹**: è¿ç»­2æ¬¡ç›¸ä¼¼æœç´¢æ— è¿›å±•â†’ç«‹å³æ”¹å˜ç­–ç•¥
5. **ä»…è¾“å‡ºç­”æ¡ˆ**: ä¸¥æ ¼åªè¾“å‡ºç­”æ¡ˆæ–‡æœ¬
6. **æ—¥æœŸ/æ•°å­—ç²¾ç¡®**: åŠ¡å¿…ç²¾ç¡®åŒ¹é…
7. **å¿…é¡»å›ç­”**: ç¦æ­¢è¾“å‡º"æ— æ³•ç¡®å®š"

### Skills ä½¿ç”¨å»ºè®®
- åˆæ¬¡æœç´¢æŸä¸ªä¸»é¢˜ â†’ ä½¿ç”¨ **smart-search**
- æ‰¾åˆ°å€™é€‰ç­”æ¡ˆå â†’ ä½¿ç”¨ **multi-source-verify** éªŒè¯
- å¤æ‚é—®é¢˜æˆ–ç½®ä¿¡åº¦ä¸­ç­‰ â†’ ä½¿ç”¨ **chain-of-verification**
- éœ€è¦å¤šæ­¥æ·±åº¦ç ”ç©¶ â†’ ä½¿ç”¨ **deep-research**

### æ€è€ƒæ¨¡å¼
Action â†’ Observation â†’ Reflection â†’ Action ... â†’ Final Answer

"""
                        f"{FEW_SHOT_EXAMPLES}"
                    ),
                },
                {"role": "user", "content": self.question},
            ]


class QueryResponse(BaseModel):
    answer: str


@app.post("/")
async def query(req: QueryRequest) -> QueryResponse:
    MAX_RETRIES = 2
    final_answer = ""
    rejection_history = []
    candidate_pool = CandidatePool()

    # ğŸ”¥ åŠ¨æ€è®¡ç®—æœ€å¤§æ­¥æ•°ï¼ˆæ–¹æ¡ˆ2ï¼‰
    max_steps = calculate_max_steps(req.question, base_steps=20)
    print(f"[Monitoring] Dynamic max_steps calculated: {max_steps} for question: {req.question[:50]}...")

    for attempt in range(MAX_RETRIES + 1):
        if attempt > 0:
            print(f"[Monitoring] Query Retry {attempt}/{MAX_RETRIES} for question: {req.question[:50]}...")

        result = ""
        agent_state = None

        messages = req.to_messages()
        if rejection_history:
            hint_text = "\n\n".join(rejection_history)
            rejected_names = candidate_pool.get_rejected_names()

            messages.append({
                "role": "system",
                "content": f"SYSTEM REMINDER: You previously attempted to answer this question but were REJECTED by verification.\n\nPREVIOUS REJECTIONS:\n{hint_text}\n\nREJECTED CANDIDATES (DO NOT REPEAT):\n{rejected_names}\n\nCRITICAL INSTRUCTION:\n1. You MUST change your search strategy completely\n2. Explore DIFFERENT countries/persons (NOT {rejected_names})\n3. If you believe the rejected candidate is actually correct, provide EXPLICIT evidence for ALL missing constraints\n4. Consider using excluded_entities parameter in smart-search to force diversification"
            })

        async for chunk in agent_loop(messages, [web_search, web_fetch, browse_page, extract_entities, x_keyword_search, search_pdf_attachment, browse_pdf_attachment, multi_hop_search, get_weather], max_steps=max_steps):
            if chunk.type == "tool_call" or chunk.type == "tool_call_result":
                result = ""
            elif chunk.type == "text" and chunk.content:
                result += chunk.content
            elif chunk.type == "final_state":
                try:
                    state_data = json.loads(chunk.content)
                    agent_state = state_data.get("state", {})
                    candidates = (agent_state.get("meta") or {}).get("candidates", [])
                    for cand in candidates:
                        candidate_pool.add_candidate(
                            answer=cand.get("text", ""),
                            confidence=cand.get("confidence", 0.0),
                            sources=[f"source_{i}" for i in range(cand.get("sources", 1))]
                        )
                    print(f"[CandidatePool] Extracted {len(candidates)} candidates from agent_loop")
                except Exception as e:
                    print(f"[CandidatePool] Failed to extract candidates: {e}")

        if result:
            result = clean_answer(result)
            result = check_answer_type(req.question, result)

        if result:
            original = result
            verified = verify_answer(req.question, result)

            if "[REJECTED]" in verified:
                 print(f"[Monitoring] Answer rejected by verification (Attempt {attempt}): {verified}")

                 candidate_pool.reject(original, verified)
                 next_candidate = candidate_pool.get_next_best()

                 if next_candidate and next_candidate != original:
                     print(f"[CandidatePool] Switching to next candidate: '{next_candidate}'")
                     result = next_candidate
                     verified = verify_answer(req.question, result)

                     retry_count = 0
                     while "[REJECTED]" in verified and retry_count < 3:
                         candidate_pool.reject(result, verified)
                         next_candidate = candidate_pool.get_next_best()
                         if not next_candidate or next_candidate == result:
                             break
                         print(f"[CandidatePool] Candidate rejected, trying next: '{next_candidate}'")
                         result = next_candidate
                         verified = verify_answer(req.question, result)
                         retry_count += 1

                     if "[REJECTED]" not in verified:
                         result = verified
                         final_answer = clean_answer(result)
                         if final_answer:
                             print(f"[CandidatePool] Found valid candidate from pool: '{final_answer[:50]}...'")
                             break

                 rejection_history.append(f"Attempt {attempt+1}: {verified}")

                 if attempt == MAX_RETRIES:
                     print(f"[Monitoring] Max retries reached. Forcing fix for rejected candidate...")
                     fixed_ans = await force_fix_answer(req.question, original, verified)
                     if fixed_ans:
                         result = fixed_ans
                         final_answer = fixed_ans
                         break

                 result = ""
            else:
                 if verified != original:
                     print(f"[Monitoring] Verified answer: '{original[:50]}...' -> '{verified[:50]}...'")
                 result = verified

        if result:
            final_answer = clean_answer(result)
            if final_answer:
                break

    return QueryResponse(answer=final_answer)


@app.post("/stream")
async def stream(req: QueryRequest) -> StreamingResponse:
    async def stream_response():
        async for chunk in agent_loop(req.to_messages(), [web_search, web_fetch, browse_page, extract_entities, x_keyword_search, search_pdf_attachment, browse_pdf_attachment, multi_hop_search, get_weather], max_steps=15):
            if chunk.type == "text" and chunk.content:
                data = {"answer": chunk.content}
                yield f"data: {json.dumps(data, ensure_ascii=False)}\n\n"
    
    return StreamingResponse(
        stream_response(),
        media_type="text/event-stream",
    )

if _AGUI_AVAILABLE:
    @app.post("/ag-ui")
    async def ag_ui(run_agent_input: RunAgentInput) -> StreamingResponse:
        messages = to_openai_messages(run_agent_input.messages)
        async def stream_response():
            async for event in stream_agui_events(
                chunks=agent_loop(messages, [web_search, web_fetch, browse_page, extract_entities, x_keyword_search, search_pdf_attachment, browse_pdf_attachment, multi_hop_search, get_weather], max_steps=30),
                run_agent_input=run_agent_input,
            ):
                yield to_sse_data(event)
        return StreamingResponse(
            stream_response(),
            media_type="text/event-stream",
        )


if __name__ == "__main__":
    import uvicorn
    port = int(os.getenv("PORT", "8000"))
    try:
        uvicorn.run(app, host="0.0.0.0", port=port)
    except Exception:
        uvicorn.run(app, host="0.0.0.0", port=8001)
